# HNDSI Basic Network Function Prototypes
# Jonathan H. Morgan
# 22 September 2021

# Basic Functions: More Functions to Be Added
#   netread
#   netwrite

# Clear Out Console Script
  cat("\014")
  
#########################
#   GENERAL FUNCTIONS   #
#########################

# Options
  options(stringsAsFactors = FALSE)
  options(mc.cores = parallel::detectCores())

###############################
#   EXAMPLE CASE: AHS_WPVAR   #
###############################

setwd('/Users/jonathan.h.morgan/Desktop/DNAC/IDEANet/Data_Scripts')
import_data <- function(file_csv) {
  
  # Installing Necessary Packages 
    list.of.packages <- c('readr')
    new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
    if(length(new.packages)) install.packages(new.packages)
    rm(list.of.packages, new.packages)
    
  # Reading-In CSV with readr
    file_csv <- paste0(file_csv, '.csv')
    base_data <- readr::read_csv(file_csv, col_names = TRUE)
    
  # Creating Stacked Edgelist
    communities <- vector('list', length(unique(base_data$commcnt)))
    community_ids <- sort(unique(base_data$commcnt))
    names(communities) <- community_ids
    
    for (i in seq_along(communities)) {
      community <- base_data[base_data$commcnt == community_ids[[i]], ]
      egos <- sort(unique(community$ego_nid))
      
      alters <- vector('list', length(egos))
      names(alters) <- egos
      
      for (j in seq_along(egos)) {
        ego <- community[community$ego_nid == egos[[j]], ]
        m_friends <- as.data.frame(as.integer(ego[,c(4:8)]))
        m_friends <- cbind('Male', m_friends)
        colnames(m_friends) <- c('gender','alter_id')
        
        f_friends <- as.data.frame(as.integer(ego[,c(14:18)]))
        f_friends <- cbind('Female', f_friends)
        colnames(f_friends) <- c('gender','alter_id')
        
        alter_net <- rbind(m_friends, f_friends)
        alter_net <- cbind(egos[[j]], alter_net)
        alter_net <- cbind(community_ids[[i]], alter_net)
        colnames(alter_net)[c(1:2)] <- c('commcnt', 'ego_nid')
        
        alters[[j]] <- alter_net
        
        rm(alter_net, ego, m_friends, f_friends)
      }
      
      communities[[i]] <- do.call("rbind", alters)
      
      rm(community, egos, alters)
    }
  
  # Assigning communities edglist to the Global Environment
    assign(x = 'communities_edgelist', value = communities,.GlobalEnv)  
    
  return(base_data)
}

base_data <- import_data('ahs_wpvar')

# Focusing on Community One for Demonstration Purposes
  community_1 <- communities_edgelist[[1]]
  community_2 <- communities_edgelist[[2]]
  
################
#   netwrite   #
################
  
# Notes:
#   nodelist assumes a single vector of node labels/ids. Numeric ids are generated by the function that are used when creating the network objects.
#   https://igraph.org/r/doc/get.edge.ids.html
#   Multiplex network requires an edgelist specification with a vector, type, that is the same length as the 
#   vector lengths of the i and j elements.

# Currently Supported Packages (Will Add Pajek, ORA, UCINet, etc)
  support_packages <- c('igraph', 'network')
  
  netwrite <- function(data_type = c('edgelist'), adjacency_matrix=FALSE, adjacency_list=FALSE,
                       nodelist=FALSE, i_elements=FALSE, j_elements=FALSE, weights=FALSE, type=FALSE,
                       package='igraph', missing_code=99999, weight_type='frequency', 
                       directed=FALSE, net_name='network') {
    
  # Installing Necessary Packages 
    list.of.packages <- c('dplyr', 'igraph', 'network', 'ggplot2', 'cowplot', 'moments')
    new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
    if(length(new.packages)) install.packages(new.packages)
    rm(list.of.packages, new.packages)
    
  # Setting Data Type: Adjacency Matrix, Adjacency List, or Edgelist
    if(data_type == 'adjacency_matrix'){
      # Checking for ID Column
        if (dim(adjacency_matrix)[[1]] != dim(adjacency_matrix)[[2]]){
          adjacency_matrix <- adjacency_matrix[,c(2:ncol(adjacency_matrix))]
        }else{
          adjacency_matrix <- adjacency_matrix[,]
        }    
      
      # Generating Network Object
        if (package == 'igraph') {
          if(as.logical(directed) == TRUE){
            # Generating directed graph
              g <- igraph::graph_from_adjacency_matrix(adjacency_matrix, mode=c('directed'), diag = TRUE)
              
            # Creating Nodes File with Node-Level Measures
              edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
              nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
              colnames(nodes) <- c('id')
              nodes$id <- nodes$id - 1
              
            # Create an alternate closeness function
              closeness <- function(g){ 
                geo <- 1/igraph::distances(g, mode='out')
                diag(geo) <- 0 # Define self-ties as 0
                apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
              }
              
            # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
              reachable <- function(g){
                # Isolating the node's ego-network, the number of reachable nodes, and calculating 
                # the proportion of the total
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  if(directed == TRUE){
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                  }else{
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Adding Node-Level Measures
              total_degree <- igraph::degree(g, mode='all', loops=FALSE)
              weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
              in_degree <- igraph::degree(g, mode='in', loops=FALSE)
              out_degree <- igraph::degree(g, mode='out', loops=FALSE)
              closeness <- closeness(g)
              betweenness <- igraph::betweenness(g, directed=as.logical(directed))
              bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
              eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
              constraint <- igraph::constraint(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Isolating the graph's components
                  components <- igraph::clusters(g, mode="weak")
                  biggest_cluster_id <- which.max(components$csize)
                
                # Extracting the ids of the largest component
                  largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
                
                # Extracting Subgraph
                  largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
              
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Extracting bi-components
                  bi_components <- igraph::biconnected_components(g)
                  bi_component_list <- as.list(bi_components$components)
                  bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                  bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                  colnames(bi_lengths) <- c('list_id', 'length')
                  largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                  largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                  rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
                # Extracting Subgraph
                  largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                      one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                    }else{
                      one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                    }
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    # If a named nodelist else an unnamed list
                    if(length(names(igraph::V(g))) == length(igraph::V(g))){
                      if(names(igraph::V(g))[[1]] == "0"){
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                        }
                      }else{
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                        }
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                      }
                    }
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    rm(paths)
                  }
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                  proportion_two_step <- vector('numeric', length(one_step_paths))
                  for(i in seq_along(proportion_two_step)) {
                    # Identifying Nodes that Occur in Both Two and One-Step Paths
                      shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                  
                    # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                      proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                  }
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step)
              }  
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
              reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
              trans_rate(g)
              global_clustering_coefficient <- igraph::transitivity(g, type='global')
              average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
          }else{
            # Generating undirected graph
              g <- igraph::graph_from_adjacency_matrix(adjacency_matrix, mode=c('undirected'), diag = FALSE)
              
            # Creating Nodes File with Node-Level Measures
              edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
              nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
              colnames(nodes) <- c('id')
              nodes$id <- nodes$id - 1
              
            # Create an alternate closeness function
              closeness <- function(g){ 
                geo <- 1/igraph::distances(g, mode='out')
                diag(geo) <- 0 # Define self-ties as 0
                apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
              }
              
            # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
              reachable <- function(g){
                # Isolating the node's ego-network, the number of reachable nodes, and calculating 
                # the proportion of the total
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  if(directed == TRUE){
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }else{
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Adding Node-Level Measures
              total_degree <- igraph::degree(g, mode='all', loops=FALSE)
              weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
              in_degree <- igraph::degree(g, mode='in', loops=FALSE)
              out_degree <- igraph::degree(g, mode='out', loops=FALSE)
              closeness <- closeness(g)
              betweenness <- igraph::betweenness(g, directed=as.logical(directed))
              bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
              eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
              constraint <- igraph::constraint(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Isolating the graph's components
                  components <- igraph::clusters(g, mode="weak")
                  biggest_cluster_id <- which.max(components$csize)
                
                # Extracting the ids of the largest component
                  largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
                
                # Extracting Subgraph
                  largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
            
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Extracting bi-components
                  bi_components <- igraph::biconnected_components(g)
                  bi_component_list <- as.list(bi_components$components)
                  bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                  bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                  colnames(bi_lengths) <- c('list_id', 'length')
                  largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                  largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                  rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
                # Extracting Subgraph
                  largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                      one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                    }else{
                      one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                    }
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    # If a named nodelist else an unnamed list
                    if(length(names(igraph::V(g))) == length(igraph::V(g))){
                      if(names(igraph::V(g))[[1]] == "0"){
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                        }
                      }else{
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                        }
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                      }
                    }
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    rm(paths)
                  }
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                  proportion_two_step <- vector('numeric', length(one_step_paths))
                  for(i in seq_along(proportion_two_step)) {
                    # Identifying Nodes that Occur in Both Two and One-Step Paths
                      shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                  
                    # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                      proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                  }
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step)
              }  
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
              reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
              trans_rate(g)
              global_clustering_coefficient <- igraph::transitivity(g, type='global')
              average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
          }
        }else if (package == 'network'){
          if(as.logical(directed) == TRUE){
            # Outputting a directed graph
              g <- network::network(adjacency_matrix, ignore.eval=FALSE,
                                    names.eval='a')
            
            # Specifying network metric commands
              if (directed == TRUE) {
                gmode <- 'digraph'
                cmode <- 'directed'
              }else{
                gmode <- 'graph'
                cmode <- 'undirected'
              }
              
            # Extracting nodes
              edges <- as.matrix(g, matrix.type="edgelist")
              nodes <- as.data.frame(sort(unique(c(edges[,1], edges[,2]))))
              colnames(nodes) <- c('id')
              
            # Create an alternate closeness function
              closeness <- function(g){           # Create an alternate closeness function!
                geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
                diag(geo) <- 0                    # Define self-ties as 0
                apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
              }
              
            # Reachability function
              reachable <- function(g){
                # Calculating the proportion reacable for each node
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  for(i in seq_along(proportion_reachable)){
                    # Getting all reachable pairs
                      reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                    # Isolating ego network
                      ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                    # Elminating Self-Loops
                      ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                      rm(reachable_edges, ego_net)
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Function calculating Burt's constraint measure
              constraint.orig <- function(g) {
                # Sub-setting Adjacency Matrix
                  idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                  A <- network::as.matrix.network.adjacency(g)
                  A <- A[idx, idx]
                  n <- sum(idx)
                
                # Calculating constraint meatures
                  one <- c(rep(1,n))
                  CZ <- A + t(A)
                  cs <- CZ %*% one                      # degree of vertices
                  ics <- 1/cs
                  CS <- ics %*% t(one)                  # 1/degree of vertices
                  P <- CZ * CS                          # intermediate result: proportionate tie strengths
                  PSQ <- P%*%P                          # sum paths of length two
                  P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                  PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                  ci <- PC %*% one                      # overall constraint
                  dim(ci) <- NULL
                
                # Assigning scores to node ids
                  ci2 <- nodes$id
                  ci2[idx] <- ci
                  ci2[!idx] <- NaN
                
                # Assigning final scores to global environment
                  assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
              }
            
            # Adding node-level measures
              total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
              weighted_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=FALSE)
              in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
              out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
              closeness <- closeness(g)
              betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
              bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
              eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
              constraint <- constraint.orig(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Identifying Largest Component IDs
                  largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                  largest_component_ids <- cbind(nodes[1], largest_component_ids)
                  largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
                
                # Extracting Largest Component as a It's Own Graph
                  lgc <- sna::component.largest(g,connected="weak", result='graph')
                  largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                  rm(lgc)
                
                # Assigning Objects to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
              
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Identifying largest weak bi-component
                  bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                  bi_components <- bi_components$members
                  bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                  bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                  colnames(bi_component_sizes)[[2]] <- c('component_id')
                  bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                  bi_components <- bi_components[[bi_component_sizes]]
                  rm(bi_component_sizes)
                
                # Creating ID list
                  bi_component_ids <- as.data.frame(bi_components)
                  bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                  colnames(bi_component_ids)[[1]] <- c('id')
                
                # Inducing sub-graph 
                  largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                  rm(bi_components)
              } 
              
            # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
              assortativity_degree <- function(edgelist, g) {
                # Extracting the graph's edgelist
                  if(as.logical(directed) == TRUE){
                    edges <- as.data.frame(edgelist[,c(3,5)])
                  }else{
                    edges_1 <- as.data.frame(edgelist[,c(3,5)])
                    edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
                  
                    edges_2 <- as.data.frame(edgelist[,c(5,3)])
                    edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
                    names(edges_2) <- c('i_id', 'j_id', 'Obs_ID')
                  
                    edges <- rbind(edges_1, edges_2)
                    edges <- edges[order(edges$Obs_ID), ]
                    edges <- edges[!(edges$i_id == edges$j_id), ]
                    edges <- edges[, c(1:2)]
                    
                    rm(edges_1, edges_2)
                  }
                
                # Calculating the total degree for each node
                  node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                  node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
                
                # Joining i & j ids
                  colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                  colnames(edges)[[3]] <- c('i_degree')
                
                  colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                  colnames(edges)[[4]] <- c('j_degree')
                  rm(node_degree)
                
                # Calculating the Pearson Correlation of i and j degree variables
                  degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
                
                # Assigning correlation value to the global environment
                  assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    for(j in seq_along(one_step_paths[[i]])) {
                      paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                    }
                    paths <- sort(unique(unlist(paths)))
                    two_step_paths[[i]] <- paths
                    rm(paths)
                  }
                
                # Identifying Shared Paths & Getting the Length
                  shared_paths <- vector('list', nrow(nodes))
                  for(i in seq_along(shared_paths)) {
                    shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                  }
                  shared_paths <- as.numeric(unlist(shared_paths))
                
                # Getting the Number of Two-Step Paths
                  two_step_paths <- lapply(two_step_paths, function(x) length(x))
                  two_step_paths <- as.numeric(unlist(two_step_paths))
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                  proportion_two_step <- shared_paths/two_step_paths
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
              }
              
            # Calculating the Average Geodesic Distance
              average_geodesic <- function(g) {
                # Generating the number and lengths of all geodesics between all nodes
                  gd <- sna::geodist(g, count.paths = FALSE)
                
                # Extracting the distances
                  geodesics <- gd$gdist
                  geodesics <- geodesics[(lower.tri(geodesics))]
                
                # Replacing infinite values with 0 for the purposes of calculating the average
                  geodesics <- geodesics[!is.infinite(geodesics)]
                
                # Calculating the average shortest path length
                  average_path_length <- mean(geodesics)
                
                # Assgining to the global environment       
                  assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                  rm(gd, geodesics)
              }
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              assortativity_degree(edgelist, g)
              reciprocity_rate <- ifelse(as.logical(directed) == TRUE, sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
              trans_rate(g)
              global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
              average_geodesic(g)
          }else{
            # Outputting undirected graph
              g <- network::network(adjacency_matrix, ignore.eval=FALSE,
                                    names.eval='a', directed=TRUE)
            
            # Specifying network metric commands
              if (directed == TRUE) {
                gmode <- 'digraph'
                cmode <- 'directed'
              }else{
                gmode <- 'graph'
                cmode <- 'undirected'
              }
              
            # Extracting nodes
              edges <- as.matrix(g, matrix.type="edgelist")
              edges_1 <- as.data.frame(edges)
              edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
              
            # Making edgelist symmetric
              edges_2 <- as.data.frame(edges[,c(2,1)])
              edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
              names(edges_2) <- c('V1', 'V2', 'Obs_ID')
              
              edges <- rbind(edges_1, edges_2)
              edges <- edges[order(edges$Obs_ID), ]
              edges <- edges[!(edges$V1 == edges$V2), ]
              edges <- edges[, c(1:2)]
              rm(edges_1, edges_2)
              
              nodes <- as.data.frame(sort(unique(c(edges[,1], edges[,2]))))
              colnames(nodes) <- c('id')
              
            # Generating undirected graph
              g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
              
            # Adding Edges
              el <- edges
              el[,1] <- as.character(el[,1])
              el[,2] <- as.character(el[,2])
              g <- network::add.edges(g, el[,1], el[,2])
              rm(el)
              
            # Create an alternate closeness function
              closeness <- function(g){           # Create an alternate closeness function!
                geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
                diag(geo) <- 0                    # Define self-ties as 0
                apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
              }
              
            # Reachability function
              reachable <- function(g){
                # Calculating the proportion reacable for each node
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  for(i in seq_along(proportion_reachable)){
                    # Getting all reachable pairs
                      reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                    # Isolating ego network
                      ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                    # Elminating Self-Loops
                      ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                      rm(reachable_edges, ego_net)
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Function calculating Burt's constraint measure
              constraint.orig <- function(g) {
                # Sub-setting Adjacency Matrix
                  idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                  A <- network::as.matrix.network.adjacency(g)
                  A <- A[idx, idx]
                  n <- sum(idx)
                
                # Calculating constraint meatures
                  one <- c(rep(1,n))
                  CZ <- A + t(A)
                  cs <- CZ %*% one                      # degree of vertices
                  ics <- 1/cs
                  CS <- ics %*% t(one)                  # 1/degree of vertices
                  P <- CZ * CS                          # intermediate result: proportionate tie strengths
                  PSQ <- P%*%P                          # sum paths of length two
                  P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                  PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                  ci <- PC %*% one                      # overall constraint
                  dim(ci) <- NULL
                
                # Assigning scores to node ids
                  ci2 <- nodes$id
                  ci2[idx] <- ci
                  ci2[!idx] <- NaN
                
                # Assigning final scores to global environment
                  assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
              }
              
            # Adding node-level measures
              total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
              weighted_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=FALSE)
              in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
              out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
              closeness <- closeness(g)
              betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
              bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
              eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
              constraint <- constraint.orig(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Identifying Largest Component IDs
                  largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                  largest_component_ids <- cbind(nodes[1], largest_component_ids)
                  largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
                
                # Extracting Largest Component as a It's Own Graph
                  lgc <- sna::component.largest(g,connected="weak", result='graph')
                  largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                  rm(lgc)
                
                # Assigning Objects to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
            
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Identifying largest weak bi-component
                  bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                  bi_components <- bi_components$members
                  bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                  bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                  colnames(bi_component_sizes)[[2]] <- c('component_id')
                  bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                  bi_components <- bi_components[[bi_component_sizes]]
                  rm(bi_component_sizes)
                
                # Creating ID list
                  bi_component_ids <- as.data.frame(bi_components)
                  bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                  colnames(bi_component_ids)[[1]] <- c('id')
                
                # Inducing sub-graph 
                  largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                  rm(bi_components)
              } 
              
            # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
              assortativity_degree <- function(edgelist, g) {
                # Extracting the graph's edgelist
                  edges <- as.data.frame(edges)
                  
                # Calculating the total degree for each node
                  node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                  node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
                
                # Joining i & j ids
                  colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                  colnames(edges)[[3]] <- c('i_degree')
                
                  colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                  colnames(edges)[[4]] <- c('j_degree')
                  rm(node_degree)
                
                # Calculating the Pearson Correlation of i and j degree variables
                  degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
                
                # Assigning correlation value to the global environment
                  assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    for(j in seq_along(one_step_paths[[i]])) {
                      paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                    }
                    paths <- sort(unique(unlist(paths)))
                    two_step_paths[[i]] <- paths
                    rm(paths)
                  }
                
                # Identifying Shared Paths & Getting the Length
                  shared_paths <- vector('list', nrow(nodes))
                  for(i in seq_along(shared_paths)) {
                    shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                  }
                  shared_paths <- as.numeric(unlist(shared_paths))
                
                # Getting the Number of Two-Step Paths
                  two_step_paths <- lapply(two_step_paths, function(x) length(x))
                  two_step_paths <- as.numeric(unlist(two_step_paths))
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                  proportion_two_step <- shared_paths/two_step_paths
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
              }
              
            # Calculating the Average Geodesic Distance
              average_geodesic <- function(g) {
                # Generating the number and lengths of all geodesics between all nodes
                  gd <- sna::geodist(g, count.paths = FALSE)
                
                # Extracting the distances
                  geodesics <- gd$gdist
                  geodesics <- geodesics[(lower.tri(geodesics))]
                
                # Replacing infinite values with 0 for the purposes of calculating the average
                  geodesics <- geodesics[!is.infinite(geodesics)]
                
                # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
                
                # Assgining to the global environment       
                  assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                  rm(gd, geodesics)
              }
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              assortativity_degree(edgelist, g)
              reciprocity_rate <- ifelse(as.logical(directed) == TRUE,sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
              trans_rate(g)
              global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
              average_geodesic(g)
          }
        }else{
          print('Network package not supported.')
        }
      
      # Outputting Network Object to the Global Environment
        assign(x = net_name, value = g,.GlobalEnv)
        assign(x = 'nodes', value = nodes, .GlobalEnv)
    }else if(data_type == 'adjacency_list'){
      # Is the adjacency list a list
        if(class(adjacency_list) == 'list'){
          g <- igraph::graph_from_adj_list(adjacency_list, mode="out")
        }else{
          # Converting to a list
            adj_list <- vector('list', dim(adjacency_list)[[1]])
            names(adj_list) <- as.character(adjacency_list[,1])
            for(i in seq_along(adj_list)){
              adj_row <- unique(as.integer(strsplit(adjacency_list[i,2], ' ')[[1]]))
              adj_list[[i]] <- vector('list', length(adj_row))
              for(j in seq_along(adj_row)) {
                adj_list[[i]][[j]] <- adj_row[[j]]
              }
              rm(adj_row)
            }
          
          # Generating network from adjacency list
            g <- igraph::graph_from_adj_list(adj_list, mode="out")
        }
      
      # Generating network object
        if (package == 'igraph') {
          # Copying igraph object
            g <- g
          
          # Creating Nodes File with Node-Level Measures
            edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
            nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
            colnames(nodes) <- c('id')
            nodes$id <- nodes$id - 1
            
          # Create an alternate closeness function
            closeness <- function(g){ 
              geo <- 1/igraph::distances(g, mode='out')
              diag(geo) <- 0                            # Define self-ties as 0
              apply(geo, 1, sum)                        # Return sum(1/geodist) for each vertex
            }
            
          # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
            reachable <- function(g){
              # Isolating the node's ego-network, the number of reachable nodes, and calculating 
              # the proportion of the total
                proportion_reachable <- vector('numeric', nrow(nodes))
                if(directed == TRUE){
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                  
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }else{
                for(i in seq_along(proportion_reachable)){
                  # Isolating connected vertices
                    ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                  
                  # Eliminating self-loops
                    ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                  
                  # Calculating the proportion reachable
                    proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                    rm(ego_net)
                }
              }
              
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Adding Node-Level Measures
            total_degree <- igraph::degree(g, mode='all', loops=FALSE)
            weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
            in_degree <- igraph::degree(g, mode='in', loops=FALSE)
            out_degree <- igraph::degree(g, mode='out', loops=FALSE)
            closeness <- closeness(g)
            betweenness <- igraph::betweenness(g, directed=as.logical(directed))
            bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
            eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
            constraint <- igraph::constraint(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Isolating the graph's components
                components <- igraph::clusters(g, mode="weak")
                biggest_cluster_id <- which.max(components$csize)
              
              # Extracting the ids of the largest component
                largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
              
              # Extracting Subgraph
                largest_component <- igraph::induced_subgraph(g, largest_component_ids)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Extracting bi-components
                bi_components <- igraph::biconnected_components(g)
                bi_component_list <- as.list(bi_components$components)
                bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                colnames(bi_lengths) <- c('list_id', 'length')
                largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                rm(bi_components, bi_component_list, bi_lengths, largest_id)
              
              # Extracting Subgraph
                largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                    one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                  }else{
                    one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                  }
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  # If a named nodelist else an unamed list
                  if(length(names(igraph::V(g))) == length(igraph::V(g))){
                    if(names(igraph::V(g))[[1]] == "0"){
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                      }
                    }
                  }else{
                    for(j in seq_along(paths)) {
                      paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                    }
                  }
                  two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  rm(paths)
                }
                
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                proportion_two_step <- vector('numeric', length(one_step_paths))
                for(i in seq_along(proportion_two_step)) {
                  # Identifying Nodes that Occur in Both Two and One-Step Paths
                    shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                
                  # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                    proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                }
              
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step)
            }  
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
            reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
            trans_rate(g)
            global_clustering_coefficient <- igraph::transitivity(g, type='global')
            average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
        }else if (package == 'network') {
          # Getting Edgelist: iGraph
            edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
            colnames(edges) <- c('i_id', 'j_id')
            
          # Checking if there are edge values
            if (length(igraph::get.edge.attribute(g)) > 0) {
              edge_values <- as.data.frame(igraph::get.edge.attribute(g))
              edges <- cbind(edges, edge_values)
              rm(edge_values)
            }else{
              edges$weight <- 1
            }
            
          # Making Symmetric if Undirected
            if(as.logical(directed) ==TRUE) {
              edges <- edges
            }else{
              edges_1 <- as.data.frame(edges)
              edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
              
              edges_2 <- as.data.frame(edges[,c(2,1,3)])
              edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
              names(edges_2) <- c('i_id', 'j_id', 'weight', 'Obs_ID')
              
              edges <- rbind(edges_1, edges_2)
              edges <- edges[order(edges$Obs_ID), ]
              edges <- edges[!(edges$i_id == edges$j_id), ]
              edges <- edges[, c(1:3)]
              rm(edges_1, edges_2)
            }
          
          # Extracting nodelist
            adj_ids <- igraph::get.adjlist(g, mode='all')
            nodes <- as.data.frame(seq(1, length(adj_ids), 1))
            colnames(nodes)[[1]] <- c('id')
            rm(adj_ids)
            
          # Generating network data object
            g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
            
            el <- edges[,c(1,2)]
            el[,1] <- as.character(el[,1])
            el[,2] <- as.character(el[,2])
            g <- network::add.edges(g, el[,1], el[,2])
            
          # Adding Node-Level Measures
            if (directed == TRUE) {
              gmode <- 'digraph'
              cmode <- 'directed'
            }else{
              gmode <- 'graph'
              cmode <- 'undirected'
            }
            
          # Create an alternate closeness function
            closeness <- function(g){           # Create an alternate closeness function!
              geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
              diag(geo) <- 0                    # Define self-ties as 0
              apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
            }
            
          # Reachability function
            reachable <- function(g){
              # Calculating the proportion reacable for each node
                proportion_reachable <- vector('numeric', nrow(nodes))
                for(i in seq_along(proportion_reachable)){
                  # Getting all reachable pairs
                    reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                
                  # Isolating ego network
                    ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                
                  # Elminating Self-Loops
                    ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                
                # Calculating the proportion reachable
                    proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                    rm(reachable_edges, ego_net)
              }
              
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Function calculating Burt's constraint measure
            constraint.orig <- function(g) {
              # Sub-setting Adjacency Matrix
                idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                A <- network::as.matrix.network.adjacency(g)
                A <- A[idx, idx]
                n <- sum(idx)
              
              # Calculating constraint meatures
                one <- c(rep(1,n))
                CZ <- A + t(A)
                cs <- CZ %*% one                      # degree of vertices
                ics <- 1/cs
                CS <- ics %*% t(one)                  # 1/degree of vertices
                P <- CZ * CS                          # intermediate result: proportionate tie strengths
                PSQ <- P%*%P                          # sum paths of length two
                P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                ci <- PC %*% one                      # overall constraint
                dim(ci) <- NULL
              
              # Assigning scores to node ids
                ci2 <- nodes$id
                ci2[idx] <- ci
                ci2[!idx] <- NaN
              
              # Assigning final scores to global environment
                assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
            }
            
            total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
            weighted_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=FALSE)
            in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
            out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
            closeness <- closeness(g)
            betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
            bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
            eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
            constraint <- constraint.orig(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Identifying Largest Component IDs
                largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                largest_component_ids <- cbind(nodes[1], largest_component_ids)
                largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
              
              # Extracting Largest Component as a It's Own Graph
                lgc <- sna::component.largest(g,connected="weak", result='graph')
                largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                rm(lgc)
              
              # Assigning Objects to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
          
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Identifying largest weak bi-component
                bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                bi_components <- bi_components$members
                bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                colnames(bi_component_sizes)[[2]] <- c('component_id')
                bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                bi_components <- bi_components[[bi_component_sizes]]
                rm(bi_component_sizes)
              
              # Creating ID list
                bi_component_ids <- as.data.frame(bi_components)
                bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                colnames(bi_component_ids)[[1]] <- c('id')
              
              # Inducing sub-graph 
                largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                rm(bi_components)
            } 
          
          # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
            assortativity_degree <- function(edges, g) {
              # Calculating the total degree for each node
                node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
              
              # Joining i & j ids
                colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                colnames(edges)[[4]] <- c('i_degree')
              
                colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                colnames(edges)[[5]] <- c('j_degree')
                rm(node_degree)
              
              # Calculating the Pearson Correlation of i and j degree variables
                degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
              
              # Assigning correlation value to the global environment
                assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  for(j in seq_along(one_step_paths[[i]])) {
                    paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                  }
                  paths <- sort(unique(unlist(paths)))
                  two_step_paths[[i]] <- paths
                  rm(paths)
                }
              
              # Identifying Shared Paths & Getting the Length
                shared_paths <- vector('list', nrow(nodes))
                for(i in seq_along(shared_paths)) {
                  shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                }
                shared_paths <- as.numeric(unlist(shared_paths))
              
              # Getting the Number of Two-Step Paths
                two_step_paths <- lapply(two_step_paths, function(x) length(x))
                two_step_paths <- as.numeric(unlist(two_step_paths))
              
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                proportion_two_step <- shared_paths/two_step_paths
              
              # Transitivity Rate
              transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
            }
          
          # Calculating the Average Geodesic Distance
            average_geodesic <- function(g) {
              # Generating the number and lengths of all geodesics between all nodes
                gd <- sna::geodist(g, count.paths = FALSE)
              
              # Extracting the distances
                geodesics <- gd$gdist
                geodesics <- geodesics[(lower.tri(geodesics))]
                
              # Replacing infinite values with 0 for the purposes of calculating the average
                geodesics <- geodesics[!is.infinite(geodesics)]
              
              # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
              
              # Assgining to the global environment       
                assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                rm(gd, geodesics)
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            assortativity_degree(edges, g)
            reciprocity_rate <- ifelse(as.logical(directed) == TRUE, sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
            trans_rate(g)
            global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
            average_geodesic(g)
        }else {
          print('Network package not supported.')
        }
        
      # Outputting network object to global environment
        assign(x = net_name, value = g,.GlobalEnv)
        assign(x = 'nodes', value = nodes, .GlobalEnv)
    }else{
      # Creating Canonical Node and Edgelists
        if(weights==FALSE){
          edgelist <-as.matrix(cbind(i_elements, j_elements))
          edgelist <-cbind(edgelist, rep(1,nrow(edgelist)))
          colnames(edgelist)[[3]] <- c('weight')
        }else{
          edgelist <-as.matrix(cbind(i_elements, j_elements, weights))
        }
      
        edgelist <- edgelist[!(rowSums(is.na(edgelist))), ]
        edgelist <- edgelist[edgelist[,1] != missing_code & edgelist[,2] != missing_code, ] 
        edgelist <- cbind(seq(1,nrow(edgelist), 1), edgelist)
        colnames(edgelist)[[1]] <- c('Obs_ID')
        
      # Adding Nodes
        if(nodelist == FALSE) {
          nodes <- as.data.frame(sort(unique(c(edgelist[,2], edgelist[,3]))))
          nodes <- cbind(seq(1,nrow(nodes),1), nodes)
          colnames(nodes) <- c('id', 'label')
          
          senders <- as.data.frame(edgelist[,c(1:2)])
          colnames(senders)[[2]] <- c('label')
          senders <- dplyr::left_join(senders, nodes, by='label')
          colnames(senders)[c(2,3)] <- c('i_elements', 'i_id')
          
          targets <- as.data.frame(edgelist[,c(1,3,4)])
          colnames(targets)[[2]] <- c('label')
          targets <- dplyr::left_join(targets, nodes, by='label')
          colnames(targets)[c(2,4)] <- c('j_elements', 'j_id')
          targets <- targets[c(1,2,4,3)]
          
          edgelist <- dplyr::left_join(senders, targets, by='Obs_ID')
          edgelist <- edgelist[order(edgelist$i_id, edgelist$j_id), ]
          edgelist <- as.matrix(edgelist)
          rm(senders, targets)
        }else{
          nodes <- nodelist
          
          nodes <- cbind(as.data.frame(seq(1, length(nodes), 1)), nodes)
          colnames(nodes) <- c('id', 'label')
          
          senders <- as.data.frame(edgelist[,c(1:2)])
          colnames(senders)[[2]] <- c('label')
          senders <- dplyr::left_join(senders, nodes, by='label')
          colnames(senders)[c(2,3)] <- c('i_elements', 'i_id')
          
          targets <- as.data.frame(edgelist[,c(1,3,4)])
          colnames(targets)[[2]] <- c('label')
          targets <- dplyr::left_join(targets, nodes, by='label')
          colnames(targets)[c(2,4)] <- c('j_elements', 'j_id')
          targets <- targets[c(1,2,4,3)]
          
          edgelist <- dplyr::left_join(senders, targets, by='Obs_ID')
          edgelist <- edgelist[order(edgelist$i_id, edgelist$j_id), ]
          edgelist <- as.matrix(edgelist)
          rm(senders, targets)
        }
        
      # Create Graph Objects
        if(package == 'igraph'){
          # Make Zero-Indexed
            nodes$id <- nodes$id - 1
            edgelist[,3] <- edgelist[,3] - 1
            edgelist[,5] <- edgelist[,5] - 1
            
          # Make Weights Reflect Frequency Rather than Distance
            if(weight_type == 'frequency') {
              edgelist[,6] <- 1/edgelist[,6]
            }else{
              edgelist[,6] <- edgelist[,6]
            }
            
          # Creating igraph object
            colnames(nodes)[[2]] <- c('attr')
            g <- igraph::graph_from_data_frame(d = edgelist[,c(3,5)], directed = as.logical(directed), vertices = nodes) 
            
          # Adding edge weights
            igraph::edge.attributes(g)$weight <- edgelist[,6]
            
          # Create an alternate closeness function
            closeness <- function(g){ 
              geo <- 1/igraph::distances(g, mode='out')
              diag(geo) <- 0 # Define self-ties as 0
              apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
            }
            
          # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
            reachable <- function(g){
              # Isolating the node's ego-network, the number of reachable nodes, and calculating 
              # the proportion of the total
                proportion_reachable <- vector('numeric', nrow(nodes))
                if(directed == TRUE){
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                      
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                      
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }else{
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }
                
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Adding Node-Level Measures
            total_degree <- igraph::degree(g, mode='all', loops=FALSE)
            weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
            in_degree <- igraph::degree(g, mode='in', loops=FALSE)
            out_degree <- igraph::degree(g, mode='out', loops=FALSE)
            closeness <- closeness(g)
            betweenness <- igraph::betweenness(g, directed=as.logical(directed))
            bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
            eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
            constraint <- igraph::constraint(g)
            reachability <- reachable(g)
                          
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Isolating the graph's components
                components <- igraph::clusters(g, mode="weak")
                biggest_cluster_id <- which.max(components$csize)
              
              # Extracting the ids of the largest component
                largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
              
              # Extracting Subgraph
                largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Extracting bi-components
                bi_components <- igraph::biconnected_components(g)
                bi_component_list <- as.list(bi_components$components)
                bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                colnames(bi_lengths) <- c('list_id', 'length')
                largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
              # Extracting Subgraph
                largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                    one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                  }else{
                    one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                  }
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  # If a named nodelist else an unnamed list
                  if(length(names(igraph::V(g))) == length(igraph::V(g))){
                    if(names(igraph::V(g))[[1]] == "0"){
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                      }
                    }
                  }else{
                    for(j in seq_along(paths)) {
                      paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                    }
                  }
                  two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  rm(paths)
                }
              
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                proportion_two_step <- vector('numeric', length(one_step_paths))
                for(i in seq_along(proportion_two_step)) {
                  # Identifying Nodes that Occur in Both Two and One-Step Paths
                    shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                
                  # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                    proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                }
              
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step)
            }  
            
          # Calculating Multiplex Edge Correlation
            multiplex_edge_corr <- function(edgelist, type, directed) {
              if(type[[1]] != FALSE){
                if(length(type) == dim(edgelist)[[1]]) {
                  # Adding type to the edgelist
                    if('type' %in% colnames(edgelist)) {
                      edges <- as.data.frame(edgelist[,])
                    }else{
                      edges <- cbind(as.data.frame(edgelist), type)
                    }
                  
                  # Generating Correlations Either as Directed or Undirected
                    if(as.logical(directed) == TRUE) {
                      # Generating Sub-Networks Based on Type
                        types <- sort(unique(type))
                        subnets <- vector('list', length(types))
                        names(subnets) <- types
                        for(i in seq_along(types)){
                          subnets[[i]] <- as.data.frame(edges[(type == types[[i]]), ])
                          subnets[[i]] <- subnets[[i]][,c('i_id', 'j_id', 'type', 'weight')]
                          colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                          colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                        }
                    
                      # Creating a Wide Data-Set to Generate Correlations
                        ties <- unique(as.data.frame(edgelist[ ,c("i_id", "j_id")]))
                        for(i in seq_along(types)){
                          ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                          ties[is.na(ties)] <- 0
                        }
                    
                      # Calculating the Correlation for Unique Combination of Types 
                        pairs <- t(combn(paste0(types,'_','weight'), 2))
                        for(i in nrow(pairs)) {
                          column_set <- pairs[i,]
                          tie_set <- ties[,column_set]
                          multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                          rm(column_set, tie_set)
                        }
                        rm(pairs, types, subnets, ties)
                    }else{
                      # Creating a separate edgelist (Symmetric Edges) to Perform Operations
                        s_edges <- edges[,c('i_id', 'j_id', 'type', 'weight')]
                    
                      # Eliminating Duplicate Pairs
                        s_edges <- s_edges[!duplicated(t(apply(s_edges[,c(1:2)], 1, sort))),]
                    
                      # Creating Edge Groups & Glossary
                        edges_1 <- cbind(s_edges[,c(1,2)], seq(1, dim(s_edges)[[1]], 1))
                        colnames(edges_1)[[3]] <- c('edge_group')
                    
                        edges_2 <- cbind(s_edges[,c(2,1)], seq(1, dim(s_edges)[[1]], 1))
                        colnames(edges_2) <- c('i_id','j_id','edge_group')
                    
                        edges_glossary <- rbind(edges_1, edges_2)
                        edges_glossary <- edges_glossary[order(edges_glossary$edge_group), ]
                        rm(edges_1, edges_2, s_edges)
                    
                      # Joining edge_groups to edges
                        if('Obs_ID' %in% colnames(edgelist)){
                          edges <- edges
                        }else{
                          edges <- cbind(seq(1, dim(edges)[[1]], 1), edges)
                          names(edges)[[1]] <- c('Obs_ID')
                        }
                        edges <- dplyr::left_join(as.data.frame(edges), edges_glossary, by=c('i_id', 'j_id'))
                    
                      # Eliminating Duplicates Caused by Self-Loops
                        edges <- edges[!(duplicated(edges$Obs_ID)), ]
                        rm(edges_glossary)
                    
                      # Collapsing Ties and Summing Weights
                        edge_groups <- unique(edges$edge_group)
                        ties <- vector('list', length(edge_groups))
                        names(ties) <- edge_groups
                        for(i in seq_along(edge_groups)) {
                          e_group <- edges[(edges$edge_group == edge_groups[[i]]), ]
                          row.names(e_group) <- seq(1, nrow(e_group), 1)
                          e_types <- unique(e_group$type)
                          ties[[i]] <- as.data.frame(e_group$type)
                          ties[[i]]$weight <- sum(e_group$weight)
                          ties[[i]]$i_id <- e_group[1,3]
                          ties[[i]]$j_id <- e_group[1,5]
                          colnames(ties[[i]])[[1]] <- c('type')
                          ties[[i]] <- ties[[i]][,c(3,4,1,2)]
                          rm(e_group, e_types)
                        }
                        
                        ties <- do.call("rbind", ties)
                    
                      # Generating Sub-Networks Based on Type
                        types <- sort(unique(type))
                        subnets <- vector('list', length(types))
                        names(subnets) <- types
                        for(i in seq_along(types)){
                          subnets[[i]] <- ties[(ties$type == types[[i]]), ]
                          colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                          colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                        }
                    
                      # Creating a Wide Data-Set to Generate Correlations
                        ties <- unique(ties[ ,c("i_id", "j_id")])
                        for(i in seq_along(types)){
                          ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                          ties[is.na(ties)] <- 0
                        }
                    
                      # Calculating the Correlation for Unique Combination of Types 
                        pairs <- t(combn(paste0(types,'_','weight'), 2))
                        for(i in nrow(pairs)) {
                          column_set <- pairs[i,]
                          tie_set <- ties[,column_set]
                          multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                          rm(column_set, tie_set)
                        }
                        rm(pairs, types, subnets, ties)
                      }
                  
                  # Assigning final scores to global environment
                    assign(x = 'multiplex_edge_correlation', value = multiplex_edge_correlation,.GlobalEnv)  
                }else{
                  writeLines("The type indicator variable is not the same length as the network's edgelist.\nTo calculate the network's multilevel edge correlation, please supply a vector of the same length.")
                }
              }else{
                edgelist <- edgelist[,]
              }
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
            reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
            trans_rate(g)
            global_clustering_coefficient <- igraph::transitivity(g, type='global')
            average_path_length <- igraph::average.path.length(g, directed=as.logical(directed), 
                                                               unconnected = TRUE)
            multiplex_edge_corr(edgelist= edgelist[,c(3,5,6)], type=type, directed=as.logical(directed))

        }else if(package == 'network'){
          # Make Weights Reflect Distance Rather than Frequency
            if(weight_type != 'frequency') {
              edgelist[,6] <- 1/edgelist[,6]
            }else{
              edgelist[,6] <- edgelist[,6]
            }
          
          # Creating sna networks to isolate network components
            g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
          
          # Adding Edges
            el <- edgelist[,c(3,5)]
            el[,1] <- as.character(el[,1])
            el[,2] <- as.character(el[,2])
            g <- network::add.edges(g, el[,1], el[,2])
          
          # Adding Weights
            network::set.edge.value(g,"weight", edgelist[,6])
            
          # Adding Node-Level Measures
            if (directed == TRUE) {
              gmode <- 'digraph'
              cmode <- 'directed'
            }else{
              gmode <- 'graph'
              cmode <- 'undirected'
            }
            
          # Create an alternate closeness function
            closeness <- function(g){           # Create an alternate closeness function!
              geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
              diag(geo) <- 0                    # Define self-ties as 0
              apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
            }
            
          # Reachability function
            reachable <- function(g){
              # Calculating the proportion reacable for each node
                proportion_reachable <- vector('numeric', nrow(nodes))
                for(i in seq_along(proportion_reachable)){
                  # Getting all reachable pairs
                    reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                  # Isolating ego network
                    ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                  # Elminating Self-Loops
                    ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                  # Calculating the proportion reachable
                    proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                    rm(reachable_edges, ego_net)
                }
                
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Function calculating Burt's constraint measure
            constraint.orig <- function(g) {
              # Sub-setting Adjacency Matrix
                idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                A <- network::as.matrix.network.adjacency(g)
                A <- A[idx, idx]
                n <- sum(idx)
              
              # Calculating constraint meatures
                one <- c(rep(1,n))
                CZ <- A + t(A)
                cs <- CZ %*% one                      # degree of vertices
                ics <- 1/cs
                CS <- ics %*% t(one)                  # 1/degree of vertices
                P <- CZ * CS                          # intermediate result: proportionate tie strengths
                PSQ <- P%*%P                          # sum paths of length two
                P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                ci <- PC %*% one                      # overall constraint
                dim(ci) <- NULL
              
              # Assigning scores to node ids
                ci2 <- nodes$id
                ci2[idx] <- ci
                ci2[!idx] <- NaN
              
              # Assigning final scores to global environment
                assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
            }
            
            total_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
            weighted_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=FALSE)
            in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
            out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
            closeness <- closeness(g)
            betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
            bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
            eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
            constraint <- constraint.orig(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint,reachability))
          
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Identifying Largest Component IDs
                largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                largest_component_ids <- cbind(nodes[1], largest_component_ids)
                largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
            
              # Extracting Largest Component as a It's Own Graph
                lgc <- sna::component.largest(g,connected="weak", result='graph')
                largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                rm(lgc)
                
              # Assigning Objects to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Identifying largest weak bi-component
                bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                bi_components <- bi_components$members
                bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                colnames(bi_component_sizes)[[2]] <- c('component_id')
                bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                bi_components <- bi_components[[bi_component_sizes]]
                rm(bi_component_sizes)
                
              # Creating ID list
                bi_component_ids <- as.data.frame(bi_components)
                bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                colnames(bi_component_ids)[[1]] <- c('id')
                
              # Inducing sub-graph 
                largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                rm(bi_components)
            } 
            
          # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
            assortativity_degree <- function(edgelist, g) {
              # Extracting the graph's edgelist
                if(as.logical(directed) == TRUE){
                  edges <- as.data.frame(edgelist[,c(3,5)])
                }else{
                  edges_1 <- as.data.frame(edgelist[,c(3,5)])
                  edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
                  
                  edges_2 <- as.data.frame(edgelist[,c(5,3)])
                  edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
                  names(edges_2) <- c('i_id', 'j_id', 'Obs_ID')
                  
                  edges <- rbind(edges_1, edges_2)
                  edges <- edges[order(edges$Obs_ID), ]
                  edges <- edges[!(edges$i_id == edges$j_id), ]
                  edges <- edges[, c(1:2)]
                  rm(edges_1, edges_2)
                }
                  
              # Calculating the total degree for each node
                node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
              
              # Joining i & j ids
                colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                colnames(edges)[[3]] <- c('i_degree')
              
                colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                colnames(edges)[[4]] <- c('j_degree')
                rm(node_degree)
              
              # Calculating the Pearson Correlation of i and j degree variables
                degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
              
              # Assigning correlation value to the global environment
                assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
            }
            
          # Calculating the Proportion of Two-Step Paths that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                }
                
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  for(j in seq_along(one_step_paths[[i]])) {
                    paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                  }
                  paths <- sort(unique(unlist(paths)))
                  two_step_paths[[i]] <- paths
                  rm(paths)
                }
                
              # Identifying Shared Paths & Getting the Length
                shared_paths <- vector('list', nrow(nodes))
                for(i in seq_along(shared_paths)) {
                  shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                }
                shared_paths <- as.numeric(unlist(shared_paths))
                
              # Getting the Number of Two-Step Paths
                two_step_paths <- lapply(two_step_paths, function(x) length(x))
                two_step_paths <- as.numeric(unlist(two_step_paths))
                
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                proportion_two_step <- shared_paths/two_step_paths
                
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
               
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
            }
            
          # Calculating the Average Geodesic Distance
            average_geodesic <- function(g) {
              # Generating the number and lengths of all geodesics between all nodes
                gd <- sna::geodist(g, count.paths = FALSE)
                
              # Extracting the distances
                geodesics <- gd$gdist
                geodesics <- geodesics[(lower.tri(geodesics))]
                
              # Replacing infinite values with 0 for the purposes of calculating the average
                geodesics <- geodesics[!is.infinite(geodesics)]
                
              # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
                
              # Assgining to the global environment       
                assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                rm(gd, geodesics)
            }
            
          # Calculating Multiplex Edge Correlation
            multiplex_edge_corr <- function(edgelist, type, directed) {
              if(type[[1]] != FALSE){
                if(length(type) == dim(edgelist)[[1]]) {
                  # Adding type to the edgelist
                    if('type' %in% colnames(edgelist)) {
                      edges <- as.data.frame(edgelist[,])
                    }else{
                      edges <- cbind(as.data.frame(edgelist), type)
                    }
                  
                  # Generating Correlations Either as Directed or Undirected
                    if(as.logical(directed) == TRUE) {
                      # Generating Sub-Networks Based on Type
                        types <- sort(unique(type))
                        subnets <- vector('list', length(types))
                        names(subnets) <- types
                        for(i in seq_along(types)){
                          subnets[[i]] <- as.data.frame(edges[(type == types[[i]]), ])
                          subnets[[i]] <- subnets[[i]][,c('i_id', 'j_id', 'type', 'weight')]
                          colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                          colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                        }
                    
                      # Creating a Wide Data-Set to Generate Correlations
                        ties <- unique(as.data.frame(edgelist[ ,c("i_id", "j_id")]))
                        for(i in seq_along(types)){
                          ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                          ties[is.na(ties)] <- 0
                        }
                    
                      # Calculating the Correlation for Unique Combination of Types 
                        pairs <- t(combn(paste0(types,'_','weight'), 2))
                        for(i in nrow(pairs)) {
                          column_set <- pairs[i,]
                          tie_set <- ties[,column_set]
                          multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                          rm(column_set, tie_set)
                      }
                        rm(pairs, types, subnets, ties)
                  }else{
                    # Creating a separate edgelist (Symmetric Edges) to Perform Operations
                      s_edges <- edges[,c('i_id', 'j_id', 'type', 'weight')]
                    
                    # Eliminating Duplicate Pairs
                      s_edges <- s_edges[!duplicated(t(apply(s_edges[,c(1:2)], 1, sort))),]
                    
                    # Creating Edge Groups & Glossary
                      edges_1 <- cbind(s_edges[,c(1,2)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_1)[[3]] <- c('edge_group')
                    
                      edges_2 <- cbind(s_edges[,c(2,1)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_2) <- c('i_id','j_id','edge_group')
                    
                      edges_glossary <- rbind(edges_1, edges_2)
                      edges_glossary <- edges_glossary[order(edges_glossary$edge_group), ]
                      rm(edges_1, edges_2, s_edges)
                    
                    # Joining edge_groups to edges
                      if('Obs_ID' %in% colnames(edgelist)){
                        edges <- edges
                      }else{
                        edges <- cbind(seq(1, dim(edges)[[1]], 1), edges)
                        names(edges)[[1]] <- c('Obs_ID')
                      }
                      edges <- dplyr::left_join(as.data.frame(edges), edges_glossary, by=c('i_id', 'j_id'))
                    
                    # Eliminating Duplicates Caused by Self-Loops
                      edges <- edges[!(duplicated(edges$Obs_ID)), ]
                      rm(edges_glossary)
                    
                    # Collapsing Ties and Summing Weights
                      edge_groups <- unique(edges$edge_group)
                      ties <- vector('list', length(edge_groups))
                      names(ties) <- edge_groups
                      for(i in seq_along(edge_groups)) {
                        e_group <- edges[(edges$edge_group == edge_groups[[i]]), ]
                        row.names(e_group) <- seq(1, nrow(e_group), 1)
                        e_types <- unique(e_group$type)
                        ties[[i]] <- as.data.frame(e_group$type)
                        ties[[i]]$weight <- sum(e_group$weight)
                        ties[[i]]$i_id <- e_group[1,3]
                        ties[[i]]$j_id <- e_group[1,5]
                        colnames(ties[[i]])[[1]] <- c('type')
                        ties[[i]] <- ties[[i]][,c(3,4,1,2)]
                        rm(e_group, e_types)
                      }
                    
                      ties <- do.call("rbind", ties)
                    
                    # Generating Sub-Networks Based on Type
                      types <- sort(unique(type))
                      subnets <- vector('list', length(types))
                      names(subnets) <- types
                      for(i in seq_along(types)){
                        subnets[[i]] <- ties[(ties$type == types[[i]]), ]
                        colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                        colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                      }
                    
                    # Creating a Wide Data-Set to Generate Correlations
                      ties <- unique(ties[ ,c("i_id", "j_id")])
                      for(i in seq_along(types)){
                        ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                        ties[is.na(ties)] <- 0
                      }
                    
                    # Calculating the Correlation for Unique Combination of Types 
                      pairs <- t(combn(paste0(types,'_','weight'), 2))
                      for(i in nrow(pairs)) {
                        column_set <- pairs[i,]
                        tie_set <- ties[,column_set]
                        multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                        rm(column_set, tie_set)
                      }
                      rm(pairs, types, subnets, ties)
                    }
                  
                  # Assigning final scores to global environment
                    assign(x = 'multiplex_edge_correlation', value = multiplex_edge_correlation,.GlobalEnv)  
                }else{
                  writeLines("The type indicator variable is not the same length as the network's edgelist.\nTo calculate the network's multilevel edge correlation, please supply a vector of the same length.")
                }
              }else{
                edgelist <- edgelist[,]
              }
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            assortativity_degree(edgelist, g)
            reciprocity_rate <- ifelse(as.logical(directed)==TRUE,sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
            trans_rate(g)
            global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
            average_geodesic(g)
            multiplex_edge_corr(edgelist, type, as.logical(directed))
        }else{
          edgelist <- edgelist[,]
        }
        
      # Outputting Network Objects
        assign(x = 'edgelist', value = edgelist,.GlobalEnv)  
        assign(x = 'nodelist', value = nodes,.GlobalEnv)  
        assign(x = net_name, value = g,.GlobalEnv)
    }
    
  # Generating Report
    # System-Level Data Object
      if(package =='igraph') {
        # Creating Component Aggregate Measures
          num_clusters <- igraph::clusters(g, mode="weak")[[3]]
          proportion_largest <- max(igraph::clusters(g, mode="weak")[[2]])/nrow(nodes)
      
        # Creating system-level data object
          multiplex_edge_correlation <- ifelse(type==FALSE, 'Singleplex Network', multiplex_edge_correlation)
          multiplex_edge_correlation <- multiplex_edge_correlation[[1]]
      
          measure_labels <- c('Number of Components', 'Proportion in the Largest Component',
                              'Degree Assortativity', 'Reciprocity Rate', 'Transitivity Rate', 
                              'Global Clustering Coefficient', 'Average Geodesic',
                              'Multi-Level Edge Correlation')
          measure_descriptions <- c( 'The number of weak components in the graph', 
                                     'The proportion of nodes in the largest weak component of the graph',
                                     'Edgewise correlation of degree', 'The proportion of directed ties that are reciprocated',
                                     'The proportion of two-step paths that are also one-step paths',
                                     'The proportion of closed triangles to all triangles', 'The average shortest path length',
                                     'Multiplex networks edgwise correlation of relations')
        measures <- c(num_clusters, proportion_largest, degree_assortatvity, reciprocity_rate,
                      transitivity_rate, global_clustering_coefficient, average_path_length,
                      multiplex_edge_correlation)
        system_level_measures <- cbind(as.data.frame(measure_labels), measure_descriptions, measures)
      
      # Removing node-level and system-level data objects for clarity
        rm(measure_labels, measure_descriptions, num_clusters, proportion_largest, degree_assortatvity,
           reciprocity_rate, global_clustering_coefficient, average_path_length,
           multiplex_edge_correlation, measures)
      
        rm(betweenness, bonpow, closeness, constraint, eigen_cen, in_degree, out_degree,
           total_degree, weighted_degree)
      
        rm(transitivity_rate, reachability, envir = .GlobalEnv)
    }else{
      # Creating Component Aggregate Measures
        num_clusters <- sna::components(g, connected='weak')
        components <- sna::component.largest(g, connected = 'weak', result='membership')
        proportion_largest <- length(components[components==TRUE])/nrow(nodes)
        rm(components)
      
      # Creating system-level data object
        multiplex_edge_correlation <- ifelse(type==FALSE, 'Singleplex Network', multiplex_edge_correlation)
        multiplex_edge_correlation <- multiplex_edge_correlation[[1]]
      
        measure_labels <- c('Number of Components', 'Proportion in the Largest Component',
                            'Degree Assortativity', 'Reciprocity Rate', 'Transitivity Rate', 
                            'Global Clustering Coefficient', 'Average Geodesic', 'Multi-Level Edge Correlation')
        measure_descriptions <- c( 'The number of weak components in the graph', 
                                   'The proportion of nodes in the largest weak component of the graph',
                                   'Edgewise correlation of degree', 'The proportion of directed ties that are reciprocated',
                                   'The proportion of two-step paths that are also one-step paths',
                                   'The proportion of closed triangles to all triangles', 'The average shortest path length',
                                   'Multiplex networks edgwise correlation of relations')
        measures <- c(num_clusters, proportion_largest, degree_assortatvity, reciprocity_rate,
                      transitivity_rate, global_clustering_coefficient, average_path_length,
                      multiplex_edge_correlation)
        system_level_measures <- cbind(as.data.frame(measure_labels), measure_descriptions, measures)
      
      # Removing node-level and system-level data objects for clarity
        rm(measure_labels, measure_descriptions, num_clusters, proportion_largest,
           reciprocity_rate, global_clustering_coefficient, multiplex_edge_correlation, measures)
      
        rm(betweenness, bonpow, closeness, constraint, eigen_cen, in_degree, out_degree,
           reachability, total_degree, weighted_degree)
      
        rm(degree_assortatvity, transitivity_rate, average_path_length, envir = .GlobalEnv)
    }
    
    # System & Node-Level Visualizations
      x11(width=10.6806, height=7.30556)
      system_plot <- function() {
        # Creating Layout
          viz_matrix <- matrix(c(10,10,10,10,10,10,10,10,10,
                                 2,2,2,3,3,3,0,0,0,
                                 1,1,1,1,1,1,4,4,4,
                                 1,1,1,1,1,1,0,0,0,
                                 1,1,1,1,1,1,5,5,5,
                                 1,1,1,1,1,1,6,6,6,
                                 1,1,1,1,1,1,0,0,0,
                                 1,1,1,1,1,1,9,9,9,
                                 7,7,7,8,8,8,0,0,0), 
                        ncol  = 9, byrow = TRUE)
          layout(viz_matrix)
      
        # Defining degree distribution coordinates
          y_axis <- density(nodes$total_degree)$y
          x_axis <- density(nodes$total_degree)$x
          coordinates <- cbind(as.data.frame(x_axis), y_axis)
          coordinates <- coordinates[(coordinates$x_axis >= 0), ]
          x_axis <- pretty(coordinates$x_axis)
          y_axis <- pretty(coordinates$y_axis)
          x_spacer <- x_axis[c(length(x_axis))] - x_axis[c(length(x_axis)-1)]
          x_spacer <- x_spacer*0.5
          y_spacer <- y_axis[c(length(y_axis))] - y_axis[c(length(y_axis)-1)]
          y_spacer <- y_spacer*0.5
      
        # Defining Base Degree Plot
          par(mar = c(5,6,2,2),  family='HersheySerif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(min(x_axis), max(x_axis)), 
               ylim=c(min(y_axis), max(y_axis)), cex.axis=1.3, family='HersheySerif', 
               las=1, main=' ', bty='n')
              grid(lwd = 2)
      
        # Adding Margin Text
          mtext(side = 1, text = 'Total Degree', col = "black", line = 3, cex = 1.5, family='HersheySerif')
        mtext(side = 2, text = 'Density', col = "black", line = 4.5, cex = 1.5, family='HersheySerif')
      
        # Plotting Degree
          lines(coordinates$x_axis, coordinates$y_axis, col='brown', lwd=1.5)
      
        # Adding Skew and Kurtosis
          skewness <- moments::skewness(nodes$total_degree)
          kurtosis <- moments::kurtosis(nodes$total_degree)
          text(x = (max(x_axis)-x_spacer), y = (max(y_axis)-y_spacer), paste('Skewness',round(skewness, digits=2)), cex=1.3)
          text(x = (max(x_axis)-x_spacer), y = (max(y_axis)-(y_spacer*2)), paste('Kurtosis',round(kurtosis, digits=2)), cex=1.3)
      
        # Adding Title
          title(c("Total Degree Distribution"), family='serif', cex.main=2)
      
        # Populating Subplots
          for(i in seq_along(system_level_measures$measure_labels)) {
            plot_measure <- system_level_measures[i,3]
        
            plot_measure <- ifelse(i < 8, as.numeric(plot_measure), plot_measure)
            plot_measure <- ifelse(i < 8, round(plot_measure, digits=2), plot_measure)
            plot_measure <- ifelse(i == 8, trimws(gsub('Edge', '', plot_measure)), plot_measure)
        
            par(mar=c(0,0,0,0), family='serif')
            plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
                 ylim=c(1,10), axes=FALSE, main='', bty='n')
        
            text(x=5, y=9, system_level_measures[i,1], family='serif', font=2, cex=1.3)
            text(x=5, y=6.5, plot_measure, family='serif', cex=1.5)
            rm(plot_measure)
        }
      
        # Adding Plot Title
          par(mar=c(0,0,0,0), family='serif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
               ylim=c(1,10), axes=FALSE, main='', bty='n')
          text(x=5.5, y=5, 'System-Level Measures', family='serif', font=2, cex=3)
      } 
    
      g <- cowplot::as_grob(system_plot)
      p_1 <- cowplot::ggdraw(g)
    
      p_1 
    
      node_measures_plot <- function() {
        # Specifying nicer labels
          if(directed == TRUE){
            plot_labels <- c('Weighted Degree', 'In-Degree', 'Out-Degree', 'Closeness', 
                             'Betweenness', 'Bonacich Power Centrality', 'Eigenvector Centrality', 
                             'Constraint', 'Reachability')
          }else{
            plot_labels <- c('Weighted Degree', 'Closeness', 'Betweenness', 'Bonacich Power Centrality',
                             'Eigenvector Centrality', 'Constraint', 'Reachability')
          }
      
        # Isolating the measure being visualized based on whether it's directed or not
          if(directed == TRUE){
            plot_measures <- c("weighted_degree", "in_degree", "out_degree",     
                               "closeness", "betweenness", "bonpow", "eigen_cen",
                               "constraint", "reachability")
          }else{
            plot_measures <- c("weighted_degree", "closeness", "betweenness", 
                               "bonpow", "eigen_cen", "constraint", "reachability")
          }
      
        # Defining the layout used 
          if(directed == TRUE){
            viz_matrix <- matrix(c(10,10,10,10,10,10,10,10,10,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   7,7,7,8,8,8,9,9,9,
                                   7,7,7,8,8,8,9,9,9,
                                   7,7,7,8,8,8,9,9,9), 
                                ncol  = 9, byrow = TRUE)
            layout(viz_matrix)
          }else{
            viz_matrix <- matrix(c(8,8,8,8,8,8,8,8,8,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   7,7,7,0,0,0,0,0,0,
                                   7,7,7,0,0,0,0,0,0,
                                   7,7,7,0,0,0,0,0,0), 
                                  ncol  = 9, byrow = TRUE)
            layout(viz_matrix)
        }
      
        # Generating Subplot
          for(i in seq_along(plot_measures)){
            # Defining degree distribution coordinates
              y_axis <- density(nodes[,plot_measures[[i]]])$y
              x_axis <- density(nodes[,plot_measures[[i]]])$x
              coordinates <- cbind(as.data.frame(x_axis), y_axis)
              coordinates <- coordinates[(coordinates$x_axis >= min(nodes[,plot_measures[[i]]])), ]
              x_axis <- pretty(coordinates$x_axis)
              y_axis <- pretty(coordinates$y_axis)
        
          # Defining Base Degree Plot
            par(mar = c(5,6,2,2),  family='HersheySerif')
            plot(0, type='n', xlab=' ', ylab=' ', xlim=c(min(x_axis), max(x_axis)), 
                 ylim=c(min(y_axis), max(y_axis)), cex.axis=1.3, family='HersheySerif', 
                 las=1, main=' ', bty='n')
            grid(lwd = 2)
        
          # Adding Margin Text
            mtext(side = 1, text = plot_labels[[i]], col = "black", line = 3, cex = 1.3, family='HersheySerif')
        
          # Plotting Degree
            lines(coordinates$x_axis, coordinates$y_axis, col='brown', lwd=1.5)
        } 
      
        # Adding Title
          par(mar=c(0,0,0,0), family='serif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
               ylim=c(1,10), axes=FALSE, main='', bty='n')
          text(x=5.5, y=5, 'Node-Level Measures', family='serif', font=2, cex=3)
      }
    
      g <- cowplot::as_grob(node_measures_plot)
      p_2 <- cowplot::ggdraw(g)
    
      p_2
    
    # Assigning Report Elements to the Global Environment
      assign(x = 'system_measure_plot', value = p_1,.GlobalEnv)  
      assign(x = 'node_measure_plot', value = p_2,.GlobalEnv)
      assign(x = 'system_level_measures', value = system_level_measures, .GlobalEnv)
      dev.off()
  }
  
# Evoking a Custom Plot Window
  x11(width=10.6806, height=7.30556)
    
# Edgelist Example
  netwrite(data_type = c('edgelist'), adjacency_matrix=FALSE, adjacency_list=FALSE,
           nodelist=FALSE, i_elements=community_2$ego_nid, j_elements=community_2$alter_id, weights=FALSE,
           type=FALSE, package='igraph', missing_code=99999, weight_type='frequency', 
           directed='TRUE', net_name='net_1')
  
  par(mar=c(0,0,0,0))
  plot(net_1)
  
  par(mar=c(0,0,0,0))
  plot(largest_component)
  
  par(mar=c(0,0,0,0))
  plot(largest_bi_component)
  
  system_measure_plot

  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
# Creating a type vector for the purposes of test netwrite's multiplex edge correlation function
  types <- c(1, 2)
  type <- sample(types, dim(edgelist)[[1]], replace=TRUE)
  rm(types)
  
  netwrite(data_type = c('edgelist'), adjacency_matrix=FALSE, adjacency_list=FALSE,
           nodelist=FALSE, i_elements=community_2$ego_nid, j_elements=community_2$alter_id, weights=FALSE,
           type=type, package='network', missing_code=99999, weight_type='frequency', 
           directed='FALSE', net_name='net_2')
  
  par(mar=c(0,0,0,0))
  plot(net_2)
  
  par(mar=c(0,0,0,0))
  plot(largest_component)
  
  par(mar=c(0,0,0,0))
  plot(largest_bi_component)
  
  system_measure_plot
  
  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
# Adjacency Matrix Example
  edges <- as.data.frame(as.matrix(net_2, matrix.type="edgelist"))
  edges <- cbind(seq(1, nrow(edges), 1), edges)
  colnames(edges) <- c('Obs_ID', 'i_id', 'j_id')
  
  adj_mat <- matrix(nrow=105, ncol=105)
  for(i in seq_along(edges$Obs_ID)){
    edge <- edges[i, ]
    adj_mat[edge$j_id, edge$i_id] <- 1
    rm(edge)
  }
  adj_mat[is.na(adj_mat)] <- 0
  colnames(adj_mat) <- seq(1, 105, 1)
  
  netwrite(data_type = c('adjacency_matrix'), adjacency_matrix=adj_mat, adjacency_list=FALSE,
           nodelist=FALSE, i_elements=FALSE, j_elements=FALSE, weights=FALSE, type=FALSE,
           package='igraph', missing_code=99999, weight_type='frequency', 
           directed='TRUE', net_name='net_3')
  
  par(mar=c(0,0,0,0))
  plot(net_3)
  
  system_measure_plot
  
  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
  netwrite(data_type = c('adjacency_matrix'), adjacency_matrix=adj_mat, adjacency_list=FALSE,
           nodelist=FALSE, i_elements=FALSE, j_elements=FALSE, weights=FALSE, type=FALSE,
           package='network', missing_code=99999, weight_type='frequency', 
           directed='FALSE', net_name='net_4')
  
  par(mar=c(0,0,0,0))
  plot(net_4)
  
  system_measure_plot
  
  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
# Adjacency List Example
  adjacency_list <- igraph::as_adj_list(net_1, mode='out')
  
  adj_list <- vector('list', length(adjacency_list))
  for (i in seq_along(adjacency_list)) {
    adj_row <- unique(as.integer(adjacency_list[[i]]))
    adj_row <- paste(adj_row, collapse = ' ')
    adj_list[[i]] <- adj_row
    rm(adj_row)
  }
  
  adj_list <- as.data.frame(do.call("rbind", adj_list))
  adj_list <- cbind(names(adjacency_list), adj_list)
  colnames(adj_list) <- c('ego', 'alters')
  
  netwrite(data_type = c('adjacency_list'), adjacency_matrix=FALSE, adjacency_list=adj_list,
           nodelist=FALSE, i_elements=FALSE, j_elements=FALSE, weights=FALSE, type=FALSE,
           package='network', missing_code=99999, weight_type='frequency', 
           directed='FALSE', net_name='net_5')
  
  par(mar=c(0,0,0,0))
  plot(net_5)
  
  system_measure_plot
  
  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
  netwrite(data_type = c('adjacency_list'), adjacency_matrix=FALSE, adjacency_list=adj_list,
           nodelist=FALSE, i_elements=FALSE, j_elements=FALSE, weights=FALSE, type=FALSE,
           package='igraph', missing_code=99999, weight_type='frequency', 
           directed='TRUE', net_name='net_6')
  
  par(mar=c(0,0,0,0))
  plot(net_6)
  
  system_measure_plot
  
  node_measure_plot
  
  rm(largest_component, largest_component_ids, largest_bi_component, largest_bicomponent_ids,
     system_level_measures, system_measure_plot, node_measure_plot)
  
###############
#   netread   #
###############

netread <- function(package="network", network_object=network) {
  # Network Control Logic
    if(package == "network"){
      # Getting Edgelist
        edges <- as.data.frame(network::as.edgelist(network_object))
        colnames(edges) <- c('i_id', 'j_id')
        
      # Checking if there are edge values
        if(length(network::list.edge.attributes(network_object)[network::list.edge.attributes(network_object) != "na"]) >= 1){
          edge_attribute <- network::list.edge.attributes(network_object)[network::list.edge.attributes(network_object) != "na"]
          edge_value <- network::get.edge.value(network_object, edge_attribute, unlist = TRUE, na.omit = TRUE, null.na = FALSE, deleted.edges.omit = TRUE)
          edges$weight <- edge_value
        }else{
          edges$weight <- 1
        }
        
      # Extracting Nodelist 
        nodes <- network::get.vertex.attribute(network_object, "vertex.names")
        nodes <- as.data.frame(cbind(seq(1, length(nodes), 1), nodes))
        colnames(nodes) <- c('id', 'label')
        rm(edge_value)
    }else if (package == 'igraph'){
      # Getting Edgelist: iGraph
        edges <- as.data.frame(igraph::as_edgelist(network_object, names=FALSE))
        colnames(edges) <- c('i_id', 'j_id')
        
      # Checking if there are edge values
        if (length(igraph::get.edge.attribute(network_object)) > 0) {
         edge_values <- as.data.frame(igraph::get.edge.attribute(network_object))
         edges <- cbind(edges, edge_values)
        }else{
          edges$weight <- 1
        }
        
      # Extracting nodelist
        nodes <- as.data.frame(igraph::get.vertex.attribute(network_object))
        colnames(nodes)[[1]] <- c('id')
        nodes$id <- as.numeric(nodes$id)
        nodes$id <- nodes$id + 1
        rm(edge_values)
    } else {
      network_object <- network_object
      print('Package Not Supported')
    }
  
    # Outputting Network Objects
      assign(x = 'edges', value = edges,.GlobalEnv)  
      assign(x = 'nodes', value = nodes,.GlobalEnv)  
}

netread(package='network', network_object=network)

#############
#   NOTES   #
#############

# Calculating Flow Hierarchy (http://web.mit.edu/~cmagee/www/documents/28-DetectingEvolvingPatterns_FlowHierarchy.pdf)
  flow_hierarchy <- function(g){
    # Notes: Luo and Magee's algorithm computes the flow hierarchy through exponentiation of the adjacency matrix.  This function implements an
    # An alternative approach is to  find all the strongly connected components.
    # An edge is in a cycle if and only if it is in a strongly connected component
    
    if(igraph::is.directed(g) == TRUE){
      # Generate a sorted list of strongly connected components
        scc <- igraph::components(g, mode='strong')
        scc <- as.data.frame(cbind(seq(1, length(igraph::V(g)), 1), as.integer(scc[[1]])))
        colnames(scc) <- c('node_id', 'component_id')

      # Assigning vertex ids and component ids 
        g <- igraph::set_vertex_attr(g, "components", index = igraph::V(g), as.factor(scc$component_id ))
        g <- igraph::set.vertex.attribute(g,'name',index=igraph::V(g),as.character(1:igraph::vcount(g)))
        
      # Calculating the node weights for each node for each component 
      # Node weights are the weighted degree of each node
        components <- sort(unique(scc$component_id))
        weights <- vector('list', length(components))
        names(weights) <- components
        for(i in seq_along(components)){
          c <- components[[i]]
          sub_ids <- sort(scc[(scc$component_id == c), ][[1]]) 
          g.sub <- igraph::induced.subgraph(graph=g, vids=sub_ids)
          sub_weights <- igraph::strength(g.sub, vids=igraph::V(g.sub), mode='all')
          sub_ids <- as.integer(igraph::get.vertex.attribute(g.sub, 'name'))
          c_weights <- as.data.frame(cbind(sub_ids, sub_weights))
          colnames(c_weights) <- c('node_id', 'node_weight')
          weights[[i]] <- c_weights
          rm(c, g.sub, sub_weights, sub_ids )
        }
        
        weights <- do.call("rbind", weights)
        scc <- dplyr::left_join(scc, weights, by='node_id')
        rm(weights)
          
      # Calculating the weighted degree for the full graph
        scc$graph_weight <- igraph::strength(g, vids=igraph::V(g), mode='all')
        
      # Calculating flow hierarchy
        flow_hierarchy_score <- 1 - (sum(scc$node_weight)/sum(scc$graph_weight))
        
      # Assigning Score to the Global Environment 
        assign(x = 'flow_hierarchy_score', value = flow_hierarchy_score,.GlobalEnv)  
    }else{
      print("The graph being analyzed must be a digraph to compute a flow hierarchy score")
    }
  }
  
# Add Health Example
  flow_hierarchy(net_1)
  
# Writing-Out AHS Example Data
  edgelist <- edgelist[ ,c(3,5, 6)]
  readr::write_csv(as.data.frame(edgelist), '/Users/jonathan.h.morgan/Desktop/AHS_comm2_edges.csv')
  readr::write_csv(nodelist, '/Users/jonathan.h.morgan/Desktop/AHS_com2_nodes.csv')
  
# A Star
  star <- igraph::make_star(40)
  plot(star)
  
# Extracting Edgeist and Nodelist
  star_edges <- igraph::get.edgelist(star)
  colnames(star_edges) <- c('i', 'j')
  
# Writing-Out Star Example Data & Calculating Flow Hierarchy
  readr::write_csv(as.data.frame(star_edges), '/Users/jonathan.h.morgan/Desktop/Star_edges.csv')
  flow_hierarchy(star)
  
# Florentine Families (Undirected Graph)
  library(netrankr)
  data("florentine_m")
  flo <- igraph::delete_vertices(florentine_m,which(igraph::degree(florentine_m)==0))
  plot(flo)
  
  flow_hierarchy(flo)
  
# Extracting Edgelist
  flo_edges <- igraph::get.edgelist(flo)
  
# Creating nodelist
  flo_nodes <- sort(unique(c(flo_edges[,1], flo_edges[,2])))
  flo_nodes <- cbind(as.data.frame(seq(1, length(flo_nodes), 1)), flo_nodes)
  colnames(flo_nodes) <- c('id', 'label')
  
# Assigning Numeric IDs
  flo_edges <- cbind(as.data.frame(seq(1, nrow(flo_edges), 1)), flo_edges)
  colnames(flo_edges) <- c('Obs_ID', 'i', 'j')
    
  senders <- flo_edges[,c(1:2)]
  colnames(senders)[[2]] <- c('label')
  senders <- dplyr::left_join(senders, flo_nodes, by='label')
  colnames(senders)[c(2,3)] <- c('i', 'i_id')
  
  targets <- flo_edges[,c(1,3)]
  colnames(targets)[[2]] <- c('label')
  targets <- dplyr::left_join(targets, flo_nodes, by='label')
  colnames(targets)[c(2,3)] <- c('j', 'j_id')

  flo_edges <- dplyr::left_join(senders, targets, by='Obs_ID')
  flo_edges <- flo_edges[order(flo_edges$i_id, flo_edges$j_id), ]
  flo_edges <- flo_edges[ ,c(2:5)]
  rm(senders, targets)
  
# Writing-Out Florentine Family Data
  readr::write_csv(as.data.frame(flo_nodes), '/Users/jonathan.h.morgan/Desktop/flo_nodes.csv')
  readr::write_csv(as.data.frame(flo_edges), '/Users/jonathan.h.morgan/Desktop/flo_edges.csv')
  
# Making Florentine Family Data Directed for Comparison Purposes
  netwrite(data_type = c('edgelist'), adjacency_matrix=FALSE, adjacency_list=FALSE,
           nodelist=flo_nodes$id, i_elements=flo_edges$i_id, j_elements=flo_edges$j_id, weights=FALSE,
           package='igraph', missing_code=99999, weight_type='frequency', 
           directed='TRUE', net_name='flo_net')
  
  plot(flo_net)
  flow_hierarchy(flo_net)
  flow_hierarchy_score
  
# Multiplex Network Example
  nodes <- read.csv("~/Dropbox/My Mac (Jonathan’s MacBook Pro)/Desktop/DNAC/IDEANet/Data_Scripts/Polnet2018/Data/Dataset1-Media-Example-NODES.csv", header=T, as.is=T)
  edges <- read.csv("~/Dropbox/My Mac (Jonathan’s MacBook Pro)/Desktop/DNAC/IDEANet/Data_Scripts/Polnet2018/Data/Dataset1-Media-Example-EDGES.csv", header=T, as.is=T)
  
  net <- igraph::graph_from_data_frame(d=edges, vertices=nodes, directed=TRUE)
  plot(net)
  
  igraph::E(net)$width <- 1.5
  par(mar=c(0,0,0,0))
  plot(net, edge.color=c("dark red", "slategrey")[(igraph::E(net)$type=="hyperlink")+1],
       vertex.color="gray40", layout=igraph::layout_in_circle, edge.curved=0.3, edge.arrow.size=0.4, vertex.label=NA)
  
  multiplex_edge_corr <- function(edgelist, type, directed) {
    if(type[[1]] != FALSE){
      if(length(type) == dim(edgelist)[[1]]) {
        # Generating Correlations Either as Directed or Undirected
          if(as.logical(directed) == TRUE) {
            # Generating Sub-Networks Based on Type
              types <- sort(unique(type))
              subnets <- vector('list', length(types))
              names(subnets) <- types
              for(i in seq_along(types)){
                subnets[[i]] <- edgelist[(type == types[[i]]), ]
                subnets[[i]] <- subnets[[i]][,c('i_elements', 'j_elements', 'type', 'weight')]
                colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
              }
          
            # Creating a Wide Data-Set to Generate Correlations
              ties <- unique(edgelist[c("i_elements", "j_elements")])
              for(i in seq_along(types)){
                ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_elements', 'j_elements'))
                ties[is.na(ties)] <- 0
              }
            
            # Calculating the Correlation for Unique Combination of Types 
              pairs <- t(combn(paste0(types,'_','weight'), 2))
              for(i in nrow(pairs)) {
                column_set <- pairs[i,]
                tie_set <- ties[,column_set]
                multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                rm(column_set, tie_set)
              }
              rm(pairs, types, subnets, ties)
        }else{
            # Creating a separate edgelist (Symmetric Edges) to Perform Operations
              s_edges <- edgelist[,c('i_elements', 'j_elements', 'type', 'weight')]
          
            # Eliminating Duplicate Pairs
              s_edges <- s_edges[!duplicated(t(apply(s_edges[,c(1:2)], 1, sort))),]
            
            # Creating Edge Groups & Glossary
              edges_1 <- cbind(s_edges[,c(1,2)], seq(1, dim(s_edges)[[1]], 1))
              names(edges_1)[[3]] <- c('edge_group')
            
              edges_2 <- cbind(s_edges[,c(2,1)], seq(1, dim(s_edges)[[1]], 1))
              names(edges_2) <- c('i_elements','j_elements','edge_group')
            
              edges_glossary <- rbind(edges_1, edges_2)
              edges_glossary <- edges_glossary[order(edges_glossary$edge_group), ]
              rm(edges_1, edges_2, s_edges)
            
            # Joining edge_groups to edges
              edgelist <- cbind(seq(1, dim(edgelist)[[1]], 1), edgelist)
              names(edgelist)[[1]] <- c('Obs_ID')
              edgelist <- dplyr::left_join(edgelist, edges_glossary, by=c('i_elements', 'j_elements'))
            
            # Eliminating Duplicates Caused by Self-Loops
              edgelist <- edgelist[!(duplicated(edgelist$Obs_ID)), ]
              rm(edges_glossary)
            
            # Collapsing Ties and Summing Weights
              edge_groups <- unique(edgelist$edge_group)
              ties <- vector('list', length(edge_groups))
              names(ties) <- edge_groups
              for(i in seq_along(edge_groups)) {
                e_group <- edgelist[(edgelist$edge_group == edge_groups[[i]]), ]
                e_types <- unique(e_group$type)
                e_weight <- sum(e_group$weight)
                e_elements <- e_group[1,c(2:3)]
                ties[[i]] <- as.data.frame(cbind(e_types, e_elements, e_weight))
                colnames(ties[[i]])[c(1,4)] <- c('type', 'weight')
                rm(e_group, e_types, e_weight, e_elements)
              }
            
              ties <- do.call("rbind", ties)
            
            # Generating Sub-Networks Based on Type
              types <- sort(unique(type))
              subnets <- vector('list', length(types))
              names(subnets) <- types
              for(i in seq_along(types)){
                subnets[[i]] <- ties[(ties$type == types[[i]]), ]
                subnets[[i]] <- subnets[[i]][,c('i_elements', 'j_elements', 'type', 'weight')]
                colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
              }
            
            # Creating a Wide Data-Set to Generate Correlations
              ties <- unique(ties[ ,c("i_elements", "j_elements")])
              for(i in seq_along(types)){
              ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_elements', 'j_elements'))
              ties[is.na(ties)] <- 0
            }
            
            # Calculating the Correlation for Unique Combination of Types 
              pairs <- t(combn(paste0(types,'_','weight'), 2))
              for(i in nrow(pairs)) {
              column_set <- pairs[i,]
              tie_set <- ties[,column_set]
              multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
              rm(column_set, tie_set)
            }
              rm(pairs, types, subnets, ties)
          }
        
        # Assigning final scores to global environment
          assign(x = 'multiplex_edge_correlation', value = multiplex_edge_correlation,.GlobalEnv)  
      }else{
        writeLines("The type indicator variable is not the same length as the network's edgelist.\nTo calculate the network's multilevel edge correlation, please supply a vector of the same length.")
      }
    }else{
      edgelist <- edgelist[,]
    }
  }
  
  edgelist <- edges
  colnames(edgelist)[c(1:2)] <- c('i_elements', 'j_elements')
  
  multiplex_edge_corr(edgelist, type=edgelist$type, directed)
  multiplex_edge_correlation
  
  types <- c(1, 2)
  type <- sample(types, dim(edgelist)[[1]], replace=TRUE)
  rm(types)
  
# Network Diagnostics (Two pane figure displaying system and node-level measures)
  
# Burt's constraint score based on egonet implementation
  constraint <- function(g) {
    # Creating output vector for constraint scores
      constraint_scores <- vector('numeric', nrow(nodes))
    
    # Calculating each node's constraint score
      for(i in seq_along(constraint_scores)){
        # Isolating ego-network
          dati <- (sna::ego.extract(g, ego = nodes[i, 1], neighborhood = c("combined")))[[1]]
      
        # Calculating ego's constraint
          idego <- which(rownames(dati)==as.integer(nodes[i, 1]))
          n <- dim(dati)[1]
          S <- rep(0,n)
          for( j in 1:n)  for( y in setdiff(1:n,j)) S[j] <- S[j] + (dati[j,y] + dati[y,j])
      
          Pij <- dati
          Pij[,] <- NA
          for(j in 1:n ){
            for(k in setdiff(1:n,j) ){
              Pij[j,k] <- (dati[j,k] + dati[k,j])/ S[j]
            }
          }
      
          pp <- rep(0,n)
          for (j in setdiff(1:n,idego) )
            for (q in setdiff(1:n,c(idego,j) ) )
              pp[j] <- pp[j] + Pij[idego,q]*Pij[q,j]
              constraint_scores[[i]] <- sum((Pij[idego,] + pp)^2,na.rm=T)
        }
  }
  
# Burt's constraint score based on iGraph implementation: https://github.com/igraph/rigraph/blob/dev/R/structural.properties.R
  constraint.orig <- function(g) {
      # Subsetting Adjacency Matrix
        idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
        A <- network::as.matrix.network.adjacency(g)
        A <- A[idx, idx]
        n <- sum(idx)
        
      # Calculating constraint meatures
        one <- c(rep(1,n))
        CZ <- A + t(A)
        cs <- CZ %*% one                      # degree of vertices
        ics <- 1/cs
        CS <- ics %*% t(one)                  # 1/degree of vertices
        P <- CZ * CS                          # intermediate result: proportionate tie strengths
        PSQ <- P%*%P                          # sum paths of length two
        P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
        PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
        ci <- PC %*% one                      # overall constraint
        dim(ci) <- NULL
  
      # Assigning scores to node ids
        ci2 <- nodes$id
        ci2[idx] <- ci
        ci2[!idx] <- NaN
      
      # Assigning final scores to global environment
        assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
  }
  
  n_constraint <- constraint.orig(g)
  
# iGraph Degree Assortativity
  assortativity <- function(g){
    deg <- igraph::degree(net_1)
    deg.sq <- deg^2
    m <- igraph::ecount(net_1)
    num1 <- 0; num2 <- 0; den <- 0
    edges <- igraph::get.edgelist(net_1, names=FALSE)+1
    num1 <- sum(deg[edges[,1]] * deg[edges[,2]]) / m
    num2 <- (sum(deg[edges[,1]] + deg[edges[,2]]) / (2 * m))^2
    den <- sum(deg.sq[edges[,1]] + deg.sq[edges[,2]]) / (2 * m)
    return((num1-num2)/(den-num2))
  }



