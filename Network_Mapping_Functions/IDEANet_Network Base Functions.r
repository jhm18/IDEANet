# IDEANet's netwrite and netread functions
# Jonathan H. Morgan
# 23 November 2021

# NOTE: netwrite and netread facilitate the movement from R data objects into
#       iGraph and network data objects. 
#       netwrite also produces a default set of node-level and system-level metrics
#       to facilitate the quick assessment of a given network.
#       Future iterations of netwrite and netread will incorporates tools 
#       to move data objects generated by UCINET, Pajek, Gephi, and ORA into 

# Options
  options(stringsAsFactors = FALSE)
  
# Creating Utilities Environment
  IDEANet_Utilities = new.env()

################
#   netwrite   #
################
  
# Notes:
#   nodelist assumes a single vector of node labels/ids. Numeric ids are generated 
#   by the function that are used when creating the network objects.
#   Multiplex network requires an edgelist specification with a vector, type, 
#   that is the same length as the vector lengths of the i and j elements.
#   Multiplex network metrics assume an edgelist is supplied.
  
# Arguments:
# 1) data_type: Specifies what data type will be used to generate network objects.
#               Takes 3 arguments: edgelist, adjacency_matrix, & adjacency_list
# 2) adjacency_matrix: Specifies the name of the adjacency matrix to be used if data_type = adjacency_matrix
#                      Default argument is FALSE (i.e., an adjacency matrix will not be used).
# 3) 

  IDEANet_Utilities$netwrite <- function(data_type = c('edgelist'), adjacency_matrix=FALSE, 
                                         adjacency_list=FALSE, nodelist=FALSE, i_elements=FALSE, 
                                         j_elements=FALSE, weights=FALSE, type=FALSE,
                                         package='igraph', missing_code=99999, 
                                         weight_type='frequency', directed=FALSE, 
                                         net_name='network') {
    
  # Installing Necessary Packages 
    list.of.packages <- c('dplyr', 'igraph', 'network', 'ggplot2', 'cowplot', 'moments')
    new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
    if(length(new.packages)) install.packages(new.packages)
    rm(list.of.packages, new.packages)
    
  # Setting Data Type: Adjacency Matrix, Adjacency List, or Edgelist
    if(data_type == 'adjacency_matrix'){
      # Checking for ID Column
        if (dim(adjacency_matrix)[[1]] != dim(adjacency_matrix)[[2]]){
          adjacency_matrix <- adjacency_matrix[,c(2:ncol(adjacency_matrix))]
        }else{
          adjacency_matrix <- adjacency_matrix[,]
        }    
      
      # Generating Network Object
        if (package == 'igraph') {
          if(as.logical(directed) == TRUE){
            # Generating directed graph
              g <- igraph::graph_from_adjacency_matrix(adjacency_matrix, mode=c('directed'), diag = TRUE)
              
            # Creating Nodes File with Node-Level Measures
              edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
              nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
              colnames(nodes) <- c('id')
              nodes$id <- nodes$id - 1
              
            # Create an alternate closeness function
              closeness <- function(g){ 
                geo <- 1/igraph::distances(g, mode='out')
                diag(geo) <- 0 # Define self-ties as 0
                apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
              }
              
            # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
              reachable <- function(g){
                # Isolating the node's ego-network, the number of reachable nodes, and calculating 
                # the proportion of the total
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  if(directed == TRUE){
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                  }else{
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Adding Node-Level Measures
              total_degree <- igraph::degree(g, mode='all', loops=FALSE)
              weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
              in_degree <- igraph::degree(g, mode='in', loops=FALSE)
              out_degree <- igraph::degree(g, mode='out', loops=FALSE)
              closeness <- closeness(g)
              betweenness <- igraph::betweenness(g, directed=as.logical(directed))
              bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
              eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
              constraint <- igraph::constraint(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Isolating the graph's components
                  components <- igraph::clusters(g, mode="weak")
                  biggest_cluster_id <- which.max(components$csize)
                
                # Extracting the ids of the largest component
                  largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
                
                # Extracting Subgraph
                  largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
              
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Extracting bi-components
                  bi_components <- igraph::biconnected_components(g)
                  bi_component_list <- as.list(bi_components$components)
                  bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                  bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                  colnames(bi_lengths) <- c('list_id', 'length')
                  largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                  largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                  rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
                # Extracting Subgraph
                  largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                      one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                    }else{
                      one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                    }
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    # If a named nodelist else an unnamed list
                    if(length(names(igraph::V(g))) == length(igraph::V(g))){
                      if(names(igraph::V(g))[[1]] == "0"){
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                        }
                      }else{
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                        }
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                      }
                    }
                    if(length(paths) > 0){
                      two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    }else{
                      two_step_paths[[i]] <- 0
                    }
                    rm(paths)
                  }
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                  proportion_two_step <- vector('numeric', length(one_step_paths))
                  for(i in seq_along(proportion_two_step)) {
                    # Identifying Nodes that Occur in Both Two and One-Step Paths
                      shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                  
                    # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                      proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                  }
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step)
              }  
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
              reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
              trans_rate(g)
              global_clustering_coefficient <- igraph::transitivity(g, type='global')
              average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
          }else{
            # Generating undirected graph
              g <- igraph::graph_from_adjacency_matrix(adjacency_matrix, mode=c('undirected'), diag = FALSE)
              
            # Creating Nodes File with Node-Level Measures
              edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
              nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
              colnames(nodes) <- c('id')
              nodes$id <- nodes$id - 1
              
            # Create an alternate closeness function
              closeness <- function(g){ 
                geo <- 1/igraph::distances(g, mode='out')
                diag(geo) <- 0 # Define self-ties as 0
                apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
              }
              
            # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
              reachable <- function(g){
                # Isolating the node's ego-network, the number of reachable nodes, and calculating 
                # the proportion of the total
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  if(directed == TRUE){
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }else{
                    for(i in seq_along(proportion_reachable)){
                      # Isolating connected vertices
                        ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                      # Eliminating self-loops
                        ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                      # Calculating the proportion reachable
                        proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                        rm(ego_net)
                    }
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Adding Node-Level Measures
              total_degree <- igraph::degree(g, mode='all', loops=FALSE)
              weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
              in_degree <- igraph::degree(g, mode='in', loops=FALSE)
              out_degree <- igraph::degree(g, mode='out', loops=FALSE)
              closeness <- closeness(g)
              betweenness <- igraph::betweenness(g, directed=as.logical(directed))
              bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
              eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
              constraint <- igraph::constraint(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Isolating the graph's components
                  components <- igraph::clusters(g, mode="weak")
                  biggest_cluster_id <- which.max(components$csize)
                
                # Extracting the ids of the largest component
                  largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
                
                # Extracting Subgraph
                  largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
            
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Extracting bi-components
                  bi_components <- igraph::biconnected_components(g)
                  bi_component_list <- as.list(bi_components$components)
                  bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                  bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                  colnames(bi_lengths) <- c('list_id', 'length')
                  largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                  largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                  rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
                # Extracting Subgraph
                  largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                      one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                    }else{
                      one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                    }
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    # If a named nodelist else an unnamed list
                    if(length(names(igraph::V(g))) == length(igraph::V(g))){
                      if(names(igraph::V(g))[[1]] == "0"){
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                        }
                      }else{
                        for(j in seq_along(paths)) {
                          paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                        }
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                      }
                    }
                    if(length(paths) > 0){
                      two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    }else{
                      two_step_paths[[i]] <- 0
                    }
                    rm(paths)
                  }
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                  proportion_two_step <- vector('numeric', length(one_step_paths))
                  for(i in seq_along(proportion_two_step)) {
                    # Identifying Nodes that Occur in Both Two and One-Step Paths
                      shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                  
                    # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                      proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                  }
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step)
              }  
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
              reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
              trans_rate(g)
              global_clustering_coefficient <- igraph::transitivity(g, type='global')
              average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
          }
        }else if (package == 'network'){
          if(as.logical(directed) == TRUE){
            # Outputting a directed graph
              g <- network::network(adjacency_matrix, ignore.eval=FALSE,
                                    names.eval='a')
            
            # Specifying network metric commands
              if (directed == TRUE) {
                gmode <- 'digraph'
                cmode <- 'directed'
              }else{
                gmode <- 'graph'
                cmode <- 'undirected'
              }
              
            # Extracting nodes
              edges <- as.matrix(g, matrix.type="edgelist")
              nodes <- as.data.frame(sort(unique(c(edges[,1], edges[,2]))))
              colnames(nodes) <- c('id')
              edges <- cbind(as.data.frame(seq(1, dim(edges)[[1]], 1)), edges)
              colnames(edges) <- c('Obs_ID', 'i_id', 'j_id')
              
            # Adding Weights: Elements Filled by Column then Row
              adj_elements <- c(adjacency_matrix)
              adj_weights <- adj_elements[adj_elements != 0]
              edges$weight <- adj_weights
              rm(adj_elements, adj_weights)
              
            # Calculating weighted degree
              total_weighted_degree <- function(nodes){
                # Isolating node_ids
                  node_ids <- sort(unique(nodes$id))
                  node_weights <- vector('numeric', length(node_ids))
                
                # Isolating node acting as ego and as an alter
                  for(i in seq_along(node_weights)){
                    ego <- edges[(edges[,2] == node_ids[[i]]), ]
                    alter <- edges[(edges[,3] == node_ids[[i]]), ]
                    node_edges <- rbind(ego, alter)
                    node_weights[[i]] <- sum(node_edges[,4])
                    rm(ego, alter, node_edges)
                  }
                
                # Return node_weights
                  return(node_weights)
              }   
              
            # Create an alternate closeness function
              closeness <- function(g){           # Create an alternate closeness function!
                geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
                diag(geo) <- 0                    # Define self-ties as 0
                apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
              }
              
            # Reachability function
              reachable <- function(g){
                # Calculating the proportion reacable for each node
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  for(i in seq_along(proportion_reachable)){
                    # Getting all reachable pairs
                      reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                    # Isolating ego network
                      ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                    # Elminating Self-Loops
                      ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                      rm(reachable_edges, ego_net)
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Function calculating Burt's constraint measure
              constraint.orig <- function(g) {
                # Sub-setting Adjacency Matrix
                  idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                  A <- network::as.matrix.network.adjacency(g)
                  A <- A[idx, idx]
                  n <- sum(idx)
                
                # Calculating constraint meatures
                  one <- c(rep(1,n))
                  CZ <- A + t(A)
                  cs <- CZ %*% one                      # degree of vertices
                  ics <- 1/cs
                  CS <- ics %*% t(one)                  # 1/degree of vertices
                  P <- CZ * CS                          # intermediate result: proportionate tie strengths
                  PSQ <- P%*%P                          # sum paths of length two
                  P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                  PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                  ci <- PC %*% one                      # overall constraint
                  dim(ci) <- NULL
                
                # Assigning scores to node ids
                  ci2 <- nodes$id
                  ci2[idx] <- ci
                  ci2[!idx] <- NaN
                
                # Assigning final scores to global environment
                  assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
              }
            
            # Adding node-level measures
              total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
              weighted_degree <- total_weighted_degree(nodes)
              in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
              out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
              closeness <- closeness(g)
              betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
              bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
              eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
              constraint <- constraint.orig(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Identifying Largest Component IDs
                  largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                  largest_component_ids <- cbind(nodes[1], largest_component_ids)
                  largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
                
                # Extracting Largest Component as a It's Own Graph
                  lgc <- sna::component.largest(g,connected="weak", result='graph')
                  largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                  rm(lgc)
                
                # Assigning Objects to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
              
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Identifying largest weak bi-component
                  bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                  bi_components <- bi_components$members
                  bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                  bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                  colnames(bi_component_sizes)[[2]] <- c('component_id')
                  bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                  bi_components <- bi_components[[bi_component_sizes]]
                  rm(bi_component_sizes)
                
                # Creating ID list
                  bi_component_ids <- as.data.frame(bi_components)
                  bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                  colnames(bi_component_ids)[[1]] <- c('id')
                
                # Inducing sub-graph 
                  largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                  rm(bi_components)
              } 
              
            # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
              assortativity_degree <- function(edges, g) {
                # Extracting the graph's edgelist
                  edges <- as.data.frame(edges)
                
                # Calculating the total degree for each node
                  node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                  node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
                
                # Joining i & j ids
                  colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                  colnames(edges)[[5]] <- c('i_degree')
                
                  colnames(node_degree)[[1]] <- colnames(edges)[[3]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[3]])
                  colnames(edges)[[6]] <- c('j_degree')
                  rm(node_degree)
                
                # Calculating the Pearson Correlation of i and j degree variables
                  degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
                
                # Assigning correlation value to the global environment
                  assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    for(j in seq_along(one_step_paths[[i]])) {
                      paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                    }
                    if(length(paths) > 0){
                      two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    }else{
                      two_step_paths[[i]] <- 0
                    }
                    rm(paths)
                  }
                
                # Identifying Shared Paths & Getting the Length
                  shared_paths <- vector('list', nrow(nodes))
                  for(i in seq_along(shared_paths)) {
                    shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                  }
                  shared_paths <- as.numeric(unlist(shared_paths))
                
                # Getting the Number of Two-Step Paths
                  two_step_paths <- lapply(two_step_paths, function(x) length(x))
                  two_step_paths <- as.numeric(unlist(two_step_paths))
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                  proportion_two_step <- shared_paths/two_step_paths
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
              }
              
            # Calculating the Average Geodesic Distance
              average_geodesic <- function(g) {
                # Generating the number and lengths of all geodesics between all nodes
                  gd <- sna::geodist(g, count.paths = FALSE)
                
                # Extracting the distances
                  geodesics <- gd$gdist
                  geodesics <- geodesics[(lower.tri(geodesics))]
                
                # Replacing infinite values with 0 for the purposes of calculating the average
                  geodesics <- geodesics[!is.infinite(geodesics)]
                
                # Calculating the average shortest path length
                  average_path_length <- mean(geodesics)
                
                # Assgining to the global environment       
                  assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                  rm(gd, geodesics)
              }
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              assortativity_degree(edges, g)
              reciprocity_rate <- ifelse(as.logical(directed) == TRUE, sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
              trans_rate(g)
              global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
              average_geodesic(g)
          }else{
            # Outputting undirected graph
              g <- network::network(adjacency_matrix, ignore.eval=FALSE,
                                    names.eval='a', directed=TRUE)
            
            # Specifying network metric commands
              if (directed == TRUE) {
                gmode <- 'digraph'
                cmode <- 'directed'
              }else{
                gmode <- 'graph'
                cmode <- 'undirected'
              }
              
            # Extracting nodes
              edges <- as.data.frame(as.matrix(g, matrix.type="edgelist"))
              
            # Adding Weights: Elements Filled by Column then Row
              adj_elements <- c(adjacency_matrix)
              adj_weights <- adj_elements[adj_elements != 0]
              edges$weight <- adj_weights
              rm(adj_elements, adj_weights)
              
              edges_1 <- as.data.frame(edges)
              edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
              
            # Making edgelist symmetric
              edges_2 <- as.data.frame(edges[,c(2,1,3)])
              edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
              names(edges_2) <- c('V1', 'V2', 'weight','Obs_ID')
              
              edges <- rbind(edges_1, edges_2)
              edges <- edges[order(edges$Obs_ID), ]
              edges <- edges[!(edges$V1 == edges$V2), ]
              edges <- edges[, c(1:3)]
              rm(edges_1, edges_2)
              
              nodes <- as.data.frame(sort(unique(c(edges[,1], edges[,2]))))
              colnames(nodes) <- c('id')
              
            # Generating undirected graph
              g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
              
            # Adding Edges
              el <- edges
              el[,1] <- as.character(el[,1])
              el[,2] <- as.character(el[,2])
              g <- network::add.edges(g, el[,1], el[,2])
              rm(el)
              
            # Calculating weighted degree
              total_weighted_degree <- function(nodes){
                # Isolating node_ids
                  node_ids <- sort(unique(nodes$id))
                  node_weights <- vector('numeric', length(node_ids))
                
                # Isolating node acting as ego and as an alter
                  for(i in seq_along(node_weights)){
                    ego <- edges[(edges[,1] == node_ids[[i]]), ]
                    alter <- edges[(edges[,2] == node_ids[[i]]), ]
                    node_edges <- rbind(ego, alter)
                    node_weights[[i]] <- sum(node_edges[,3])
                    rm(ego, alter, node_edges)
                  }
                
                # Return node_weights
                  return(node_weights)
              } 
              
            # Create an alternate closeness function
              closeness <- function(g){           # Create an alternate closeness function!
                geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
                diag(geo) <- 0                    # Define self-ties as 0
                apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
              }
              
            # Reachability function
              reachable <- function(g){
                # Calculating the proportion reacable for each node
                  proportion_reachable <- vector('numeric', nrow(nodes))
                  for(i in seq_along(proportion_reachable)){
                    # Getting all reachable pairs
                      reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                    # Isolating ego network
                      ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                    # Elminating Self-Loops
                      ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                      rm(reachable_edges, ego_net)
                  }
                
                # Writing to global environment
                  assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
              }
              
            # Function calculating Burt's constraint measure
              constraint.orig <- function(g) {
                # Sub-setting Adjacency Matrix
                  idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                  A <- network::as.matrix.network.adjacency(g)
                  A <- A[idx, idx]
                  n <- sum(idx)
                
                # Calculating constraint meatures
                  one <- c(rep(1,n))
                  CZ <- A + t(A)
                  cs <- CZ %*% one                      # degree of vertices
                  ics <- 1/cs
                  CS <- ics %*% t(one)                  # 1/degree of vertices
                  P <- CZ * CS                          # intermediate result: proportionate tie strengths
                  PSQ <- P%*%P                          # sum paths of length two
                  P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                  PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                  ci <- PC %*% one                      # overall constraint
                  dim(ci) <- NULL
                
                # Assigning scores to node ids
                  ci2 <- nodes$id
                  ci2[idx] <- ci
                  ci2[!idx] <- NaN
                
                # Assigning final scores to global environment
                  assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
              }
              
            # Adding node-level measures
              total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
              weighted_degree <- total_weighted_degree(nodes)
              in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
              out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
              closeness <- closeness(g)
              betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
              bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
              eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
              constraint <- constraint.orig(g)
              reachability <- reachable(g)
              
              nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                           closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
              
            # Extracting the largest weakly connected component
              largest_weak_component <- function(g){
                # Identifying Largest Component IDs
                  largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                  largest_component_ids <- cbind(nodes[1], largest_component_ids)
                  largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
                
                # Extracting Largest Component as a It's Own Graph
                  lgc <- sna::component.largest(g,connected="weak", result='graph')
                  largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                  rm(lgc)
                
                # Assigning Objects to the Global Environment
                  assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                  assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
              }
            
            # Extracting the largest bi-component
              largest_bicomponent <- function(g) {
                # Identifying largest weak bi-component
                  bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                  bi_components <- bi_components$members
                  bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                  bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                  colnames(bi_component_sizes)[[2]] <- c('component_id')
                  bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                  bi_components <- bi_components[[bi_component_sizes]]
                  rm(bi_component_sizes)
                
                # Creating ID list
                  bi_component_ids <- as.data.frame(bi_components)
                  bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                  colnames(bi_component_ids)[[1]] <- c('id')
                
                # Inducing sub-graph 
                  largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
                # Assigning the ID list and Subgraph to the Global Environment
                  assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                  assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                  rm(bi_components)
              } 
              
            # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
              assortativity_degree <- function(edges, g) {
                # Extracting the graph's edgelist
                  edges <- as.data.frame(edges)
                  
                # Calculating the total degree for each node
                  node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                  node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
                
                # Joining i & j ids
                  colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                  colnames(edges)[[4]] <- c('i_degree')
                
                  colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                  edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                  colnames(edges)[[5]] <- c('j_degree')
                  rm(node_degree)
                
                # Calculating the Pearson Correlation of i and j degree variables
                  degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
                
                # Assigning correlation value to the global environment
                  assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
              }
              
            # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
              trans_rate <- function(g) {
                # Isolating One-Step Paths
                  one_step_paths <- vector('list', nrow(nodes))
                  names(one_step_paths) <- nodes$id
                  for(i in seq_along(one_step_paths)){
                    one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                  }
                
                # Isolating Two-Step Paths
                  two_step_paths <- vector('list', nrow(nodes))
                  names(two_step_paths) <- nodes$id
                  for(i in seq_along(two_step_paths)){
                    paths <- vector('list', length(one_step_paths[[i]]))
                    for(j in seq_along(one_step_paths[[i]])) {
                      paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                    }
                    if(length(paths) > 0){
                      two_step_paths[[i]] <- sort(unique(unlist(paths)))
                    }else{
                      two_step_paths[[i]] <- 0
                    }
                    rm(paths)
                  }
                
                # Identifying Shared Paths & Getting the Length
                  shared_paths <- vector('list', nrow(nodes))
                  for(i in seq_along(shared_paths)) {
                    shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                  }
                  shared_paths <- as.numeric(unlist(shared_paths))
                
                # Getting the Number of Two-Step Paths
                  two_step_paths <- lapply(two_step_paths, function(x) length(x))
                  two_step_paths <- as.numeric(unlist(two_step_paths))
                
                # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                  proportion_two_step <- shared_paths/two_step_paths
                
                # Transitivity Rate
                  transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
                
                # Assigning transitivity_rate to the global environment
                  assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                  rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
              }
              
            # Calculating the Average Geodesic Distance
              average_geodesic <- function(g) {
                # Generating the number and lengths of all geodesics between all nodes
                  gd <- sna::geodist(g, count.paths = FALSE)
                
                # Extracting the distances
                  geodesics <- gd$gdist
                  geodesics <- geodesics[(lower.tri(geodesics))]
                
                # Replacing infinite values with 0 for the purposes of calculating the average
                  geodesics <- geodesics[!is.infinite(geodesics)]
                
                # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
                
                # Assgining to the global environment       
                  assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                  rm(gd, geodesics)
              }
              
            # Calculating System-Level Measures
              largest_weak_component(g)
              largest_bicomponent(g)
              assortativity_degree(edges, g)
              reciprocity_rate <- ifelse(as.logical(directed) == TRUE,sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
              trans_rate(g)
              global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
              average_geodesic(g)
          }
        }else{
          print('Network package not supported.')
        }
      
      # Outputting Network Object to the Global Environment
        assign(x = net_name, value = g,.GlobalEnv)
        assign(x = 'nodes', value = nodes, .GlobalEnv)
    }else if(data_type == 'adjacency_list'){
      # Is the adjacency list a list
        if(class(adjacency_list) == 'list'){
          g <- igraph::graph_from_adj_list(adjacency_list, mode="out")
        }else{
          # Converting to a list
            adj_list <- vector('list', dim(adjacency_list)[[1]])
            names(adj_list) <- as.character(adjacency_list[,1])
            for(i in seq_along(adj_list)){
              adj_row <- unique(as.integer(strsplit(adjacency_list[i,2], ' ')[[1]]))
              adj_list[[i]] <- vector('list', length(adj_row))
              for(j in seq_along(adj_row)) {
                adj_list[[i]][[j]] <- adj_row[[j]]
              }
              rm(adj_row)
            }
          
          # Generating network from adjacency list
            g <- igraph::graph_from_adj_list(adj_list, mode="out")
        }
      
      # Generating network object
        if (package == 'igraph') {
          # Copying igraph object
            g <- g
          
          # Creating Nodes File with Node-Level Measures
            edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
            nodes <- as.data.frame(sort(unique(c(edges$V1, edges$V2))))
            colnames(nodes) <- c('id')
            nodes$id <- nodes$id - 1
            
          # Create an alternate closeness function
            closeness <- function(g){ 
              geo <- 1/igraph::distances(g, mode='out')
              diag(geo) <- 0                            # Define self-ties as 0
              apply(geo, 1, sum)                        # Return sum(1/geodist) for each vertex
            }
            
          # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
            reachable <- function(g){
              # Isolating the node's ego-network, the number of reachable nodes, and calculating 
              # the proportion of the total
                proportion_reachable <- vector('numeric', nrow(nodes))
                if(directed == TRUE){
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                  
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                  
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }else{
                for(i in seq_along(proportion_reachable)){
                  # Isolating connected vertices
                    ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                  
                  # Eliminating self-loops
                    ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                  
                  # Calculating the proportion reachable
                    proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                    rm(ego_net)
                }
              }
              
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Adding Node-Level Measures
            total_degree <- igraph::degree(g, mode='all', loops=FALSE)
            weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
            in_degree <- igraph::degree(g, mode='in', loops=FALSE)
            out_degree <- igraph::degree(g, mode='out', loops=FALSE)
            closeness <- closeness(g)
            betweenness <- igraph::betweenness(g, directed=as.logical(directed))
            bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
            eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
            constraint <- igraph::constraint(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Isolating the graph's components
                components <- igraph::clusters(g, mode="weak")
                biggest_cluster_id <- which.max(components$csize)
              
              # Extracting the ids of the largest component
                largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
              
              # Extracting Subgraph
                largest_component <- igraph::induced_subgraph(g, largest_component_ids)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Extracting bi-components
                bi_components <- igraph::biconnected_components(g)
                bi_component_list <- as.list(bi_components$components)
                bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                colnames(bi_lengths) <- c('list_id', 'length')
                largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                rm(bi_components, bi_component_list, bi_lengths, largest_id)
              
              # Extracting Subgraph
                largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                    one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                  }else{
                    one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                  }
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  # If a named nodelist else an unamed list
                  if(length(names(igraph::V(g))) == length(igraph::V(g))){
                    if(names(igraph::V(g))[[1]] == "0"){
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                      }
                    }
                  }else{
                    for(j in seq_along(paths)) {
                      paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                    }
                  }
                  if(length(paths) > 0){
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  }else{
                    two_step_paths[[i]] <- 0
                  }
                  rm(paths)
                }
                
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                proportion_two_step <- vector('numeric', length(one_step_paths))
                for(i in seq_along(proportion_two_step)) {
                  # Identifying Nodes that Occur in Both Two and One-Step Paths
                    shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                
                  # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                    proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                }
              
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step)
            }  
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
            reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
            trans_rate(g)
            global_clustering_coefficient <- igraph::transitivity(g, type='global')
            average_path_length <- igraph::average.path.length(g, directed=as.logical(directed))
        }else if (package == 'network') {
          # Getting Edgelist: iGraph
            edges <- as.data.frame(igraph::as_edgelist(g, names=FALSE))
            colnames(edges) <- c('i_id', 'j_id')
            edges$weight <- rep(1, nrow(edges))
            
          # Checking if there are edge values
            if (length(igraph::get.edge.attribute(g)) > 0) {
              edge_values <- as.data.frame(igraph::get.edge.attribute(g))
              edges <- cbind(edges, edge_values)
              rm(edge_values)
            }else{
              edges$weight <- 1
            }
            
          # Making Symmetric if Undirected
            if(as.logical(directed) ==TRUE) {
              edges <- edges
            }else{
              edges_1 <- as.data.frame(edges)
              edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
              
              edges_2 <- as.data.frame(edges[,c(2,1,3)])
              edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
              names(edges_2) <- c('i_id', 'j_id', 'weight', 'Obs_ID')
              
              edges <- rbind(edges_1, edges_2)
              edges <- edges[order(edges$Obs_ID), ]
              edges <- edges[!(edges$i_id == edges$j_id), ]
              edges <- edges[, c(1:3)]
              rm(edges_1, edges_2)
            }
          
          # Extracting nodelist
            adj_ids <- igraph::get.adjlist(g, mode='all')
            nodes <- as.data.frame(seq(1, length(adj_ids), 1))
            colnames(nodes)[[1]] <- c('id')
            rm(adj_ids)
            
          # Generating network data object
            g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
            
            el <- edges[,c(1,2)]
            el[,1] <- as.character(el[,1])
            el[,2] <- as.character(el[,2])
            g <- network::add.edges(g, el[,1], el[,2])
            
          # Adding Node-Level Measures
            if (directed == TRUE) {
              gmode <- 'digraph'
              cmode <- 'directed'
            }else{
              gmode <- 'graph'
              cmode <- 'undirected'
            }
            
          # Calculating weighted degree
            total_weighted_degree <- function(nodes){
              # Isolating node_ids
                node_ids <- sort(unique(nodes$id))
                node_weights <- vector('numeric', length(node_ids))
              
              # Isolating node acting as ego and as an alter
                for(i in seq_along(node_weights)){
                  ego <- edges[(edges[,1] == node_ids[[i]]), ]
                  alter <- edges[(edges[,2] == node_ids[[i]]), ]
                  node_edges <- rbind(ego, alter)
                  node_weights[[i]] <- sum(node_edges[,3])
                  rm(ego, alter, node_edges)
                }
              
              # Return node_weights
                return(node_weights)
            } 
            
          # Create an alternate closeness function
            closeness <- function(g){           # Create an alternate closeness function!
              geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
              diag(geo) <- 0                    # Define self-ties as 0
              apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
            }
            
          # Reachability function
            reachable <- function(g){
              # Calculating the proportion reacable for each node
                proportion_reachable <- vector('numeric', nrow(nodes))
                for(i in seq_along(proportion_reachable)){
                  # Getting all reachable pairs
                    reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                
                  # Isolating ego network
                    ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                
                  # Elminating Self-Loops
                    ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                
                # Calculating the proportion reachable
                    proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                    rm(reachable_edges, ego_net)
              }
              
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Function calculating Burt's constraint measure
            constraint.orig <- function(g) {
              # Sub-setting Adjacency Matrix
                idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                A <- network::as.matrix.network.adjacency(g)
                A <- A[idx, idx]
                n <- sum(idx)
              
              # Calculating constraint meatures
                one <- c(rep(1,n))
                CZ <- A + t(A)
                cs <- CZ %*% one                      # degree of vertices
                ics <- 1/cs
                CS <- ics %*% t(one)                  # 1/degree of vertices
                P <- CZ * CS                          # intermediate result: proportionate tie strengths
                PSQ <- P%*%P                          # sum paths of length two
                P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                ci <- PC %*% one                      # overall constraint
                dim(ci) <- NULL
              
              # Assigning scores to node ids
                ci2 <- nodes$id
                ci2[idx] <- ci
                ci2[!idx] <- NaN
              
              # Assigning final scores to global environment
                assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
            }
            
            total_degree <- sna::degree(g, gmode=gmode, cmode='freeman')
            weighted_degree <- total_weighted_degree(nodes)
            in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
            out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
            closeness <- closeness(g)
            betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
            bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
            eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
            constraint <- constraint.orig(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Identifying Largest Component IDs
                largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                largest_component_ids <- cbind(nodes[1], largest_component_ids)
                largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
              
              # Extracting Largest Component as a It's Own Graph
                lgc <- sna::component.largest(g,connected="weak", result='graph')
                largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                rm(lgc)
              
              # Assigning Objects to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
          
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Identifying largest weak bi-component
                bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                bi_components <- bi_components$members
                bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                colnames(bi_component_sizes)[[2]] <- c('component_id')
                bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                bi_components <- bi_components[[bi_component_sizes]]
                rm(bi_component_sizes)
              
              # Creating ID list
                bi_component_ids <- as.data.frame(bi_components)
                bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                colnames(bi_component_ids)[[1]] <- c('id')
              
              # Inducing sub-graph 
                largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
              
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                rm(bi_components)
            } 
          
          # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
            assortativity_degree <- function(edges, g) {
              # Calculating the total degree for each node
                node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
              
              # Joining i & j ids
                colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                colnames(edges)[[4]] <- c('i_degree')
              
                colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                colnames(edges)[[5]] <- c('j_degree')
                rm(node_degree)
              
              # Calculating the Pearson Correlation of i and j degree variables
                degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
              
              # Assigning correlation value to the global environment
                assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  for(j in seq_along(one_step_paths[[i]])) {
                    paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                  }
                  if(length(paths) > 0){
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  }else{
                    two_step_paths[[i]] <- 0
                  }
                  rm(paths)
                }
              
              # Identifying Shared Paths & Getting the Length
                shared_paths <- vector('list', nrow(nodes))
                for(i in seq_along(shared_paths)) {
                  shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                }
                shared_paths <- as.numeric(unlist(shared_paths))
              
              # Getting the Number of Two-Step Paths
                two_step_paths <- lapply(two_step_paths, function(x) length(x))
                two_step_paths <- as.numeric(unlist(two_step_paths))
              
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                proportion_two_step <- shared_paths/two_step_paths
              
              # Transitivity Rate
              transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
            }
          
          # Calculating the Average Geodesic Distance
            average_geodesic <- function(g) {
              # Generating the number and lengths of all geodesics between all nodes
                gd <- sna::geodist(g, count.paths = FALSE)
              
              # Extracting the distances
                geodesics <- gd$gdist
                geodesics <- geodesics[(lower.tri(geodesics))]
                
              # Replacing infinite values with 0 for the purposes of calculating the average
                geodesics <- geodesics[!is.infinite(geodesics)]
              
              # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
              
              # Assgining to the global environment       
                assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                rm(gd, geodesics)
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            assortativity_degree(edges, g)
            reciprocity_rate <- ifelse(as.logical(directed) == TRUE, sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
            trans_rate(g)
            global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
            average_geodesic(g)
        }else {
          print('Network package not supported.')
        }
        
      # Outputting network object to global environment
        assign(x = net_name, value = g,.GlobalEnv)
        assign(x = 'nodes', value = nodes, .GlobalEnv)
    }else{
      # Creating Canonical Node and Edgelists
        if(weights[[1]]==FALSE){
          edgelist <-as.matrix(cbind(i_elements, j_elements))
          edgelist <-cbind(edgelist, rep(1,nrow(edgelist)))
          colnames(edgelist)[[3]] <- c('weight')
        }else{
          edgelist <-as.matrix(cbind(i_elements, j_elements, weights))
          colnames(edgelist)[[3]] <- c('weight')
        }
      
      # Checking for Edge Type
        if(type[[1]] == FALSE){
          edgelist <- edgelist
        }else if(length(type) == length(i_elements)){
          edgelist <- cbind(edgelist, type)
        }else{
          writeLines("The type indicator variable is not the same length as the network's edgelist.\nTo calculate the network's multilevel edge correlation, please supply a vector of the same length.")
        }
      
        edgelist <- edgelist[!(rowSums(is.na(edgelist))), ]
        edgelist <- edgelist[edgelist[,1] != missing_code & edgelist[,2] != missing_code, ] 
        edgelist <- cbind(seq(1,nrow(edgelist), 1), edgelist)
        colnames(edgelist)[[1]] <- c('Obs_ID')
        
      # Adding Nodes
        if(nodelist[[1]] == FALSE) {
          nodes <- as.data.frame(sort(unique(c(edgelist[,2], edgelist[,3]))))
          nodes <- cbind(seq(1,nrow(nodes),1), nodes)
          colnames(nodes) <- c('id', 'label')
          
          senders <- as.data.frame(edgelist[,c(1:2)])
          colnames(senders)[[2]] <- c('label')
          senders <- dplyr::left_join(senders, nodes, by='label')
          colnames(senders)[c(2,3)] <- c('i_elements', 'i_id')
          
          if(type[[1]] == FALSE){
            targets <- as.data.frame(edgelist[,c(1,3,4)])
          }else{
            targets <- as.data.frame(edgelist[,c(1,3,4, 5)])
          }
          colnames(targets)[[2]] <- c('label')
          targets <- dplyr::left_join(targets, nodes, by='label')
          if(type[[1]] == FALSE){
            colnames(targets)[c(2,4)] <- c('j_elements', 'j_id')
            targets <- targets[c(1,2,4,3)]
          }else{
            colnames(targets)[c(2,5)] <- c('j_elements', 'j_id')
            targets <- targets[c(1,2,5,3,4)]
          }
          
          edgelist <- dplyr::left_join(senders, targets, by='Obs_ID')
          edgelist <- edgelist[order(edgelist$i_id, edgelist$j_id), ]
          edgelist <- as.matrix(edgelist)
          rm(senders, targets)
        }else{
          nodes <- nodelist
          
          nodes <- cbind(as.data.frame(seq(1, length(nodes), 1)), nodes)
          colnames(nodes) <- c('id', 'label')
          
          senders <- as.data.frame(edgelist[,c(1:2)])
          colnames(senders)[[2]] <- c('label')
          senders <- dplyr::left_join(senders, nodes, by='label')
          colnames(senders)[c(2,3)] <- c('i_elements', 'i_id')
          
          if(type[[1]] == FALSE){
            targets <- as.data.frame(edgelist[,c(1,3,4)])
          }else{
            targets <- as.data.frame(edgelist[,c(1,3,4, 5)])
          }
          colnames(targets)[[2]] <- c('label')
          targets <- dplyr::left_join(targets, nodes, by='label')
          if(type[[1]] == FALSE){
            colnames(targets)[c(2,4)] <- c('j_elements', 'j_id')
            targets <- targets[c(1,2,4,3)]
          }else{
            colnames(targets)[c(2,5)] <- c('j_elements', 'j_id')
            targets <- targets[c(1,2,5,3,4)]
          }
          
          edgelist <- dplyr::left_join(senders, targets, by='Obs_ID')
          edgelist <- edgelist[order(edgelist$i_id, edgelist$j_id), ]
          edgelist <- as.matrix(edgelist)
          rm(senders, targets)
        }
    
      # Create Graph Objects
        if(package == 'igraph'){
          # Make Zero-Indexed
            nodes$id <- nodes$id - 1
            edgelist[,3] <- edgelist[,3] - 1
            edgelist[,5] <- edgelist[,5] - 1
            
          # Make Weights Reflect Frequency Rather than Distance
            if(weight_type == 'frequency') {
              edgelist[,6] <- as.numeric(1/edgelist[,6])
            }else{
              edgelist[,6] <- edgelist[,6]
            }
            
          # Creating igraph object
            colnames(nodes)[[2]] <- c('attr')
            g <- igraph::graph_from_data_frame(d = edgelist[,c(3,5)], directed = as.logical(directed), vertices = nodes) 
            
          # Adding edge weights
            igraph::edge.attributes(g)$weight <- edgelist[,6]
            
          # Create an alternate closeness function
            closeness <- function(g){ 
              geo <- 1/igraph::distances(g, mode='out')
              diag(geo) <- 0 # Define self-ties as 0
              apply(geo, 1, sum) # Return sum(1/geodist) for each vertex
            }
            
          # Reachablility function (Eliminate Loops, reaching yourself isn't that useful)
            reachable <- function(g){
              # Isolating the node's ego-network, the number of reachable nodes, and calculating 
              # the proportion of the total
                proportion_reachable <- vector('numeric', nrow(nodes))
                if(directed == TRUE){
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("out"))
                      
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                      
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }else{
                  for(i in seq_along(proportion_reachable)){
                    # Isolating connected vertices
                      ego_net <- igraph::subcomponent(g, v=igraph::V(g)[[i]], mode = c("all"))
                    
                    # Eliminating self-loops
                      ego_net <- ego_net[ego_net != igraph::V(g)[[i]]]
                    
                    # Calculating the proportion reachable
                      proportion_reachable[[i]] <- length(ego_net)/nrow(nodes)
                      rm(ego_net)
                  }
                }
                
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Adding Node-Level Measures
            total_degree <- igraph::degree(g, mode='all', loops=FALSE)
            weighted_degree <- igraph::strength(g, mode='all', loops=FALSE)
            in_degree <- igraph::degree(g, mode='in', loops=FALSE)
            out_degree <- igraph::degree(g, mode='out', loops=FALSE)
            closeness <- closeness(g)
            betweenness <- igraph::betweenness(g, directed=as.logical(directed))
            bonpow <- igraph::bonpow(g, loops=FALSE, exponent = 0.75)
            eigen_cen <- igraph::eigen_centrality(g, directed=as.logical(directed), scale=FALSE)$vector
            constraint <- igraph::constraint(g)
            reachability <- reachable(g)
                          
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint, reachability))
            
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Isolating the graph's components
                components <- igraph::clusters(g, mode="weak")
                biggest_cluster_id <- which.max(components$csize)
              
              # Extracting the ids of the largest component
                largest_component_ids <- igraph::V(g)[components$membership == biggest_cluster_id]
              
              # Extracting Subgraph
                largest_component <- igraph::induced_subgraph(g, largest_component_ids)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Extracting bi-components
                bi_components <- igraph::biconnected_components(g)
                bi_component_list <- as.list(bi_components$components)
                bi_lengths <- unlist(lapply(bi_component_list, function(x) length(x)))
                bi_lengths <- cbind(as.data.frame(seq(1, length(bi_lengths), 1)), bi_lengths)
                colnames(bi_lengths) <- c('list_id', 'length')
                largest_id <- bi_lengths[(bi_lengths$length == max(bi_lengths$length)), 1]
                largest_bicomp_ids <- sort(bi_component_list[[largest_id]])
                rm(bi_components, bi_component_list, bi_lengths, largest_id)
                
              # Extracting Subgraph
                largest_bi_component <- igraph::induced_subgraph(g, largest_bicomp_ids)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = largest_bicomp_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
            }
            
          # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  if(length(names(igraph::V(g))) == length(igraph::V(g)) ){
                    one_step_paths[[i]] <- as.integer(names(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]]))
                  }else{
                    one_step_paths[[i]] <- as.integer(igraph::neighborhood(g, order=1, mindist = 1, igraph::V(g)[[i]], mode='all')[[1]])
                  }
                }
              
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  # If a named nodelist else an unnamed list
                  if(length(names(igraph::V(g))) == length(igraph::V(g))){
                    if(names(igraph::V(g))[[1]] == "0"){
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]] + 1), mode=c('total'))))
                      }
                    }else{
                      for(j in seq_along(paths)) {
                        paths[[j]] <- as.integer(names(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total'))))
                      }
                    }
                  }else{
                    for(j in seq_along(paths)) {
                      paths[[j]] <- as.integer(igraph::neighbors(g, (one_step_paths[[i]][[j]]), mode=c('total')))
                    }
                  }
                  if(length(paths) > 0){
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  }else{
                    two_step_paths[[i]] <- 0
                  }
                  rm(paths)
                }
              
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Paths
                proportion_two_step <- vector('numeric', length(one_step_paths))
                for(i in seq_along(proportion_two_step)) {
                  # Identifying Nodes that Occur in Both Two and One-Step Paths
                    shared_paths <- sort(intersect(one_step_paths[[i]], two_step_paths[[i]]))
                
                  # Identifying the proportion of nodes that occur on both paths to the number of one-step paths
                    proportion_two_step[[i]] <- length(shared_paths)/length(two_step_paths[[i]])
                }
              
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
              
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step)
            }  
            
          # Calculating Multiplex Edge Correlation
            multiplex_edge_corr <- function(edgelist, directed) {
              if('type' %in% colnames(edgelist)){
                # Creating edgelist to manipulate internally
                  edges <- as.data.frame(edgelist[,])
                  
                # Moving back to One-Index for Comparison Purposes
                  edges[,3] <- edges[,3] + 1
                  edges[,5] <- edges[,5] + 1
                  
                # Recovering original weight for the purposes of comparison
                  if(weight_type == 'frequency') {
                    edges[,6] <- as.numeric(1/edges[,6])
                  }else{
                    edges[,6] <- edges[,6]
                  }
                
                # Generating Correlations Either as Directed or Undirected
                  if(as.logical(directed) == TRUE) {
                    # Generating Sub-Networks Based on Type
                      types <- sort(unique(type))
                      subnets <- vector('list', length(types))
                      names(subnets) <- types
                      for(i in seq_along(types)){
                        subnets[[i]] <- as.data.frame(edges[(type == types[[i]]), ])
                        subnets[[i]] <- subnets[[i]][,c('i_id', 'j_id', 'type', 'weight')]
                        colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                        colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                      }
                    
                    # Creating a Wide Data-Set to Generate Correlations
                      ties <- unique(as.data.frame(edges[ ,c("i_id", "j_id")]))
                      for(i in seq_along(types)){
                        ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                        ties[is.na(ties)] <- 0
                      }
                    
                    # Calculating the Correlation for Unique Combination of Types 
                      pairs <- t(combn(paste0(types,'_','weight'), 2))
                      for(i in nrow(pairs)) {
                        column_set <- pairs[i,]
                        tie_set <- ties[,column_set]
                        multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                        rm(column_set, tie_set)
                      }
                      rm(pairs, types, subnets, ties)
                  }else{
                    # Creating a separate edgelist (Symmetric Edges) to Perform Operations
                      s_edges <- edges[,c('i_id', 'j_id', 'type', 'weight')]
                    
                    # Eliminating Duplicate Pairs
                      s_edges <- s_edges[!duplicated(t(apply(s_edges[,c(1:2)], 1, sort))),]
                    
                    # Creating Edge Groups & Glossary
                      edges_1 <- cbind(s_edges[,c(1,2)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_1)[[3]] <- c('edge_group')
                    
                      edges_2 <- cbind(s_edges[,c(2,1)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_2) <- c('i_id','j_id','edge_group')
                    
                      edges_glossary <- rbind(edges_1, edges_2)
                      edges_glossary <- edges_glossary[order(edges_glossary$edge_group), ]
                      rm(edges_1, edges_2, s_edges)
                    
                    # Joining edge_groups to edges
                      if('Obs_ID' %in% colnames(edgelist)){
                        edges <- edges
                      }else{
                        edges <- cbind(seq(1, dim(edges)[[1]], 1), edges)
                        names(edges)[[1]] <- c('Obs_ID')
                      }
                      edges <- dplyr::left_join(as.data.frame(edges), edges_glossary, by=c('i_id', 'j_id'))
                    
                    # Eliminating Duplicates Caused by Self-Loops
                      edges <- edges[!(duplicated(edges$Obs_ID)), ]
                      rm(edges_glossary)
                    
                    # Collapsing Ties and Summing Weights
                      edge_groups <- unique(edges$edge_group)
                      ties <- vector('list', length(edge_groups))
                      names(ties) <- edge_groups
                      for(i in seq_along(edge_groups)) {
                        e_group <- edges[(edges$edge_group == edge_groups[[i]]), ]
                        row.names(e_group) <- seq(1, nrow(e_group), 1)
                        e_types <- unique(e_group$type)
                        ties[[i]] <- as.data.frame(e_group$type)
                        ties[[i]]$weight <- sum(e_group$weight)
                        ties[[i]]$i_id <- e_group[1,3]
                        ties[[i]]$j_id <- e_group[1,5]
                        colnames(ties[[i]])[[1]] <- c('type')
                        ties[[i]] <- ties[[i]][,c(3,4,1,2)]
                        rm(e_group, e_types)
                      }
                    
                      ties <- do.call("rbind", ties)
                    
                    # Generating Sub-Networks Based on Type
                      types <- sort(unique(type))
                      subnets <- vector('list', length(types))
                      names(subnets) <- types
                      for(i in seq_along(types)){
                        subnets[[i]] <- ties[(ties$type == types[[i]]), ]
                        colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                        colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                      }
                    
                    # Creating a Wide Data-Set to Generate Correlations
                      ties <- unique(ties[ ,c("i_id", "j_id")])
                      for(i in seq_along(types)){
                        ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                        ties[is.na(ties)] <- 0
                      }
                    
                    # Calculating the Correlation for Unique Combination of Types 
                      pairs <- t(combn(paste0(types,'_','weight'), 2))
                      for(i in nrow(pairs)) {
                        column_set <- pairs[i,]
                        tie_set <- ties[,column_set]
                        multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                        rm(column_set, tie_set)
                      }
                      rm(pairs, types, subnets, ties)
                  }
                  
                # Assigning final scores to global environment
                  assign(x = 'multiplex_edge_correlation', value = multiplex_edge_correlation,.GlobalEnv)  
              }else{
                edgelist <- edgelist[,]
                multiplex_edge_correlation <- 'Simplex Network'
              }
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            degree_assortatvity <- igraph::assortativity.degree(g, directed=as.logical(directed))
            reciprocity_rate <- igraph::reciprocity(g, ignore.loops = TRUE, mode='ratio')
            trans_rate(g)
            global_clustering_coefficient <- igraph::transitivity(g, type='global')
            average_path_length <- igraph::average.path.length(g, directed=as.logical(directed), 
                                                               unconnected = TRUE)
            multiplex_edge_corr(edgelist= edgelist, directed=as.logical(directed))
        }else if(package == 'network'){
          # Make Weights Reflect Distance Rather than Frequency
            if(weight_type != 'frequency') {
              edgelist[,6] <- 1/edgelist[,6]
            }else{
              edgelist[,6] <- edgelist[,6]
            }
          
          # Creating sna networks to isolate network components
            g <- network::network.initialize(nrow(nodes), directed = as.logical(directed))
          
          # Adding Edges
            el <- edgelist[,c(3,5)]
            el[,1] <- as.character(el[,1])
            el[,2] <- as.character(el[,2])
            g <- network::add.edges(g, el[,1], el[,2])
          
          # Adding Weights
            network::set.edge.value(g,"weight", edgelist[,6])
            
          # Adding Node-Level Measures
            if (directed == TRUE) {
              gmode <- 'digraph'
              cmode <- 'directed'
            }else{
              gmode <- 'graph'
              cmode <- 'undirected'
            }
            
          # Calculating weighted degree
            total_weighted_degree <- function(nodes){
              # Isolating node_ids
                node_ids <- sort(unique(nodes$id))
                node_weights <- vector('numeric', length(node_ids))
            
              # Isolating node acting as ego and as an alter
                for(i in seq_along(node_weights)){
                  ego <- edgelist[(edgelist[,3] == node_ids[[i]]), ]
                  alter <- edgelist[(edgelist[,5] == node_ids[[i]]), ]
                  node_edges <- rbind(ego, alter)
                  node_weights[[i]] <- sum(node_edges[,6])
                  rm(ego, alter, node_edges)
                }
                  
              # Return node_weights
                return(node_weights)
            }   
            
          # Create an alternate closeness function
            closeness <- function(g){           # Create an alternate closeness function!
              geo <- 1/sna::geodist(g)$gdist    # Get the matrix of 1/geodesic distance
              diag(geo) <- 0                    # Define self-ties as 0
              apply(geo, 1, sum)                # Return sum(1/geodist) for each vertex
            }
            
          # Reachability function
            reachable <- function(g){
              # Calculating the proportion reacable for each node
                proportion_reachable <- vector('numeric', nrow(nodes))
                for(i in seq_along(proportion_reachable)){
                  # Getting all reachable pairs
                    reachable_edges <- as.data.frame(sna::reachability(g, return.as.edgelist = TRUE))
                  
                  # Isolating ego network
                    ego_net <- reachable_edges[(reachable_edges$V1 == nodes[i, 1]), ]
                  
                  # Elminating Self-Loops
                    ego_net <- ego_net[(ego_net$V1 != ego_net$V2), ]
                  
                  # Calculating the proportion reachable
                    proportion_reachable[[i]] <- nrow(ego_net)/nrow(nodes)
                    rm(reachable_edges, ego_net)
                }
                
              # Writing to global environment
                assign(x = 'reachability', value = proportion_reachable,.GlobalEnv)  
            }
            
          # Function calculating Burt's constraint measure
            constraint.orig <- function(g) {
              # Sub-setting Adjacency Matrix
                idx <- sna::degree(g, diag=FALSE, gmode=gmode, cmode='freeman', ignore.eval=TRUE) != 0
                A <- network::as.matrix.network.adjacency(g)
                A <- A[idx, idx]
                n <- sum(idx)
              
              # Calculating constraint meatures
                one <- c(rep(1,n))
                CZ <- A + t(A)
                cs <- CZ %*% one                      # degree of vertices
                ics <- 1/cs
                CS <- ics %*% t(one)                  # 1/degree of vertices
                P <- CZ * CS                          # intermediate result: proportionate tie strengths
                PSQ <- P%*%P                          # sum paths of length two
                P.bi <- as.numeric(P>0)               # exclude paths to non-contacts (& reflexive):
                PC <- (P + (PSQ*P.bi))^2              # dyadic constraint
                ci <- PC %*% one                      # overall constraint
                dim(ci) <- NULL
              
              # Assigning scores to node ids
                ci2 <- nodes$id
                ci2[idx] <- ci
                ci2[!idx] <- NaN
              
              # Assigning final scores to global environment
                assign(x = 'constraint_score', value = ci2,.GlobalEnv)  
            }
            
            total_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval==TRUE)
            weighted_degree <- total_weighted_degree(nodes)
            in_degree <- sna::degree(g, gmode=gmode, cmode='indegree')
            out_degree <- sna::degree(g, gmode=gmode, cmode='outdegree')
            closeness <- closeness(g)
            betweenness <- sna::betweenness(g, gmode=gmode, cmode=cmode)
            bonpow <- as.numeric(sna::bonpow(g, gmode=gmode, exponent = 0.75))
            eigen_cen <- sna::evcent(g, gmode=gmode, rescale=FALSE)
            constraint <- constraint.orig(g)
            reachability <- reachable(g)
            
            nodes <- as.data.frame(cbind(nodes, total_degree, weighted_degree, in_degree, out_degree, 
                                         closeness, betweenness, bonpow, eigen_cen, constraint,reachability))
          
          # Extracting the largest weakly connected component
            largest_weak_component <- function(g){
              # Identifying Largest Component IDs
                largest_component_ids <- sna::component.largest(g,connected="weak", result='membership')
                largest_component_ids <- cbind(nodes[1], largest_component_ids)
                largest_component_ids <- largest_component_ids[(largest_component_ids$largest_component_ids == TRUE), ]
            
              # Extracting Largest Component as a It's Own Graph
                lgc <- sna::component.largest(g,connected="weak", result='graph')
                largest_component <- network::as.network(lgc, matrix.type = "adjacency", directed = as.logical(directed))
                rm(lgc)
                
              # Assigning Objects to the Global Environment
                assign(x = 'largest_component_ids', value = largest_component_ids,.GlobalEnv) 
                assign(x = 'largest_component', value = largest_component,.GlobalEnv) 
            }
            
          # Extracting the largest bi-component
            largest_bicomponent <- function(g) {
              # Identifying largest weak bi-component
                bi_components <- sna::bicomponent.dist(g, symmetrize=c('weak'))
                bi_components <- bi_components$members
                bi_component_sizes <- as.numeric(lapply(bi_components, FUN=length))
                bi_component_sizes <- cbind(as.data.frame(bi_component_sizes), seq(1, length(bi_component_sizes), 1))
                colnames(bi_component_sizes)[[2]] <- c('component_id')
                bi_component_sizes <- bi_component_sizes[(bi_component_sizes$bi_component_sizes == max(bi_component_sizes$bi_component_sizes)), 2]
                bi_components <- bi_components[[bi_component_sizes]]
                rm(bi_component_sizes)
                
              # Creating ID list
                bi_component_ids <- as.data.frame(bi_components)
                bi_component_ids$largest_bi_component <- as.logical(c('TRUE'))
                colnames(bi_component_ids)[[1]] <- c('id')
                
              # Inducing sub-graph 
                largest_bi_component <- network::get.inducedSubgraph(g, bi_components)
                
              # Assigning the ID list and Subgraph to the Global Environment
                assign(x = 'largest_bicomponent_ids', value = bi_component_ids,.GlobalEnv) 
                assign(x = 'largest_bi_component', value = largest_bi_component,.GlobalEnv) 
                rm(bi_components)
            } 
            
          # Calculating Degree Assortativity (Assuming Assortativity Based on Total Degree)
            assortativity_degree <- function(edgelist, g) {
              # Extracting the graph's edgelist
                if(as.logical(directed) == TRUE){
                  edges <- as.data.frame(edgelist[,c(3,5)])
                }else{
                  edges_1 <- as.data.frame(edgelist[,c(3,5)])
                  edges_1$Obs_ID <- seq(1, nrow(edges_1), 1)
                  
                  edges_2 <- as.data.frame(edgelist[,c(5,3)])
                  edges_2$Obs_ID <- seq(1, nrow(edges_1), 1)
                  names(edges_2) <- c('i_id', 'j_id', 'Obs_ID')
                  
                  edges <- rbind(edges_1, edges_2)
                  edges <- edges[order(edges$Obs_ID), ]
                  edges <- edges[!(edges$i_id == edges$j_id), ]
                  edges <- edges[, c(1:2)]
                  rm(edges_1, edges_2)
                }
                  
              # Calculating the total degree for each node
                node_degree <- sna::degree(g, gmode=gmode, cmode='freeman', ignore.eval=TRUE)
                node_degree <- as.data.frame(cbind(seq(1, length(node_degree), 1), node_degree))
              
              # Joining i & j ids
                colnames(node_degree)[[1]] <- colnames(edges)[[1]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[1]])
                colnames(edges)[[3]] <- c('i_degree')
              
                colnames(node_degree)[[1]] <- colnames(edges)[[2]]
                edges <- dplyr::left_join(edges, node_degree, by=colnames(edges)[[2]])
                colnames(edges)[[4]] <- c('j_degree')
                rm(node_degree)
              
              # Calculating the Pearson Correlation of i and j degree variables
                degree_assortatvity <- stats::cor(edges$i_degree, edges$j_degree, method='pearson')
              
              # Assigning correlation value to the global environment
                assign(x = 'degree_assortatvity', value = degree_assortatvity,.GlobalEnv)
            }
            
          # Calculating the Proportion of Two-Step Paths that Are Also One-Step Paths
            trans_rate <- function(g) {
              # Isolating One-Step Paths
                one_step_paths <- vector('list', nrow(nodes))
                names(one_step_paths) <- nodes$id
                for(i in seq_along(one_step_paths)){
                  one_step_paths[[i]] <- network::get.neighborhood(g, nodes[i,1], type=c('combined'))
                }
                
              # Isolating Two-Step Paths
                two_step_paths <- vector('list', nrow(nodes))
                names(two_step_paths) <- nodes$id
                for(i in seq_along(two_step_paths)){
                  paths <- vector('list', length(one_step_paths[[i]]))
                  for(j in seq_along(one_step_paths[[i]])) {
                    paths[[j]] <- network::get.neighborhood(g, one_step_paths[[i]][[j]], type=c('combined'))
                  }
                  if(length(paths) > 0){
                    two_step_paths[[i]] <- sort(unique(unlist(paths)))
                  }else{
                    two_step_paths[[i]] <- 0
                  }
                  rm(paths)
                }
                
              # Identifying Shared Paths & Getting the Length
                shared_paths <- vector('list', nrow(nodes))
                for(i in seq_along(shared_paths)) {
                  shared_paths[[i]] <- length(sort(intersect(as.integer(one_step_paths[[i]]), as.integer(two_step_paths[[i]]))))
                }
                shared_paths <- as.numeric(unlist(shared_paths))
                
              # Getting the Number of Two-Step Paths
                two_step_paths <- lapply(two_step_paths, function(x) length(x))
                two_step_paths <- as.numeric(unlist(two_step_paths))
                
              # Calculating the Proportion of Two-Step Path that Are Also One-Step Path
                proportion_two_step <- shared_paths/two_step_paths
                
              # Transitivity Rate
                transitivity_rate <- sum(proportion_two_step)/length(proportion_two_step)
               
              # Assigning transitivity_rate to the global environment
                assign(x = 'transitivity_rate', value = transitivity_rate,.GlobalEnv) 
                rm(one_step_paths, two_step_paths, proportion_two_step, shared_paths)
            }
            
          # Calculating the Average Geodesic Distance
            average_geodesic <- function(g) {
              # Generating the number and lengths of all geodesics between all nodes
                gd <- sna::geodist(g, count.paths = FALSE)
                
              # Extracting the distances
                geodesics <- gd$gdist
                geodesics <- geodesics[(lower.tri(geodesics))]
                
              # Replacing infinite values with 0 for the purposes of calculating the average
                geodesics <- geodesics[!is.infinite(geodesics)]
                
              # Calculating the average shortest path length
                average_path_length <- mean(geodesics)
                
              # Assgining to the global environment       
                assign(x = 'average_path_length', value = average_path_length,.GlobalEnv) 
                rm(gd, geodesics)
            }
            
          # Calculating Multiplex Edge Correlation
            multiplex_edge_corr <- function(edgelist, directed) {
              if('type' %in% colnames(edgelist)){
                # Creating edgelist to manipulate internally
                  edges <- as.data.frame(edgelist[,])
                  
                # Recovering original weight for the purposes of comparison
                  if(weight_type != 'frequency') {
                    edges[,6] <- 1/edges[,6]
                  }else{
                    edges[,6] <- edges[,6]
                  }
                  
                # Generating Correlations Either as Directed or Undirected
                  if(as.logical(directed) == TRUE) {
                    # Generating Sub-Networks Based on Type
                      types <- sort(unique(type))
                      subnets <- vector('list', length(types))
                      names(subnets) <- types
                      for(i in seq_along(types)){
                        subnets[[i]] <- as.data.frame(edges[(type == types[[i]]), ])
                        subnets[[i]] <- subnets[[i]][,c('i_id', 'j_id', 'type', 'weight')]
                        colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                        colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                      }
                  
                    # Creating a Wide Data-Set to Generate Correlations
                      ties <- unique(as.data.frame(edges[ ,c("i_id", "j_id")]))
                      for(i in seq_along(types)){
                        ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                        ties[is.na(ties)] <- 0
                      }
                  
                    # Calculating the Correlation for Unique Combination of Types 
                      pairs <- t(combn(paste0(types,'_','weight'), 2))
                      for(i in nrow(pairs)) {
                        column_set <- pairs[i,]
                        tie_set <- ties[,column_set]
                        multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                        rm(column_set, tie_set)
                      }
                      rm(pairs, types, subnets, ties)
                  }else{
                    # Creating a separate edgelist (Symmetric Edges) to Perform Operations
                      s_edges <- edges[,c('i_id', 'j_id', 'type', 'weight')]
                  
                    # Eliminating Duplicate Pairs
                      s_edges <- s_edges[!duplicated(t(apply(s_edges[,c(1:2)], 1, sort))),]
                  
                    # Creating Edge Groups & Glossary
                      edges_1 <- cbind(s_edges[,c(1,2)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_1)[[3]] <- c('edge_group')
                  
                      edges_2 <- cbind(s_edges[,c(2,1)], seq(1, dim(s_edges)[[1]], 1))
                      colnames(edges_2) <- c('i_id','j_id','edge_group')
                  
                      edges_glossary <- rbind(edges_1, edges_2)
                      edges_glossary <- edges_glossary[order(edges_glossary$edge_group), ]
                      rm(edges_1, edges_2, s_edges)
                  
                    # Joining edge_groups to edges
                      if('Obs_ID' %in% colnames(edgelist)){
                        edges <- edges
                      }else{
                        edges <- cbind(seq(1, dim(edges)[[1]], 1), edges)
                        names(edges)[[1]] <- c('Obs_ID')
                      }
                      edges <- dplyr::left_join(as.data.frame(edges), edges_glossary, by=c('i_id', 'j_id'))
                  
                    # Eliminating Duplicates Caused by Self-Loops
                      edges <- edges[!(duplicated(edges$Obs_ID)), ]
                      rm(edges_glossary)
                  
                    # Collapsing Ties and Summing Weights
                      edge_groups <- unique(edges$edge_group)
                      ties <- vector('list', length(edge_groups))
                      names(ties) <- edge_groups
                      for(i in seq_along(edge_groups)) {
                        e_group <- edges[(edges$edge_group == edge_groups[[i]]), ]
                        row.names(e_group) <- seq(1, nrow(e_group), 1)
                        e_types <- unique(e_group$type)
                        ties[[i]] <- as.data.frame(e_group$type)
                        ties[[i]]$weight <- sum(e_group$weight)
                        ties[[i]]$i_id <- e_group[1,3]
                        ties[[i]]$j_id <- e_group[1,5]
                        colnames(ties[[i]])[[1]] <- c('type')
                        ties[[i]] <- ties[[i]][,c(3,4,1,2)]
                        rm(e_group, e_types)
                      }
                  
                      ties <- do.call("rbind", ties)
                  
                    # Generating Sub-Networks Based on Type
                      types <- sort(unique(type))
                      subnets <- vector('list', length(types))
                      names(subnets) <- types
                      for(i in seq_along(types)){
                        subnets[[i]] <- ties[(ties$type == types[[i]]), ]
                        colnames(subnets[[i]])[[3]] <- names(subnets)[[i]]
                        colnames(subnets[[i]])[[4]] <- paste0(colnames(subnets[[i]])[[3]],'_',colnames(subnets[[i]])[[4]])
                      }
                  
                    # Creating a Wide Data-Set to Generate Correlations
                      ties <- unique(ties[ ,c("i_id", "j_id")])
                      for(i in seq_along(types)){
                        ties <- dplyr::left_join(ties, subnets[[i]], by=c('i_id', 'j_id'))
                        ties[is.na(ties)] <- 0
                      }
                  
                    # Calculating the Correlation for Unique Combination of Types 
                      pairs <- t(combn(paste0(types,'_','weight'), 2))
                      for(i in nrow(pairs)) {
                        column_set <- pairs[i,]
                        tie_set <- ties[,column_set]
                        multiplex_edge_correlation <- paste0('Edge Correlation for ', paste(column_set, collapse= ' and '), ': ', round(stats::cor(tie_set)[1,2], digits=2))
                        rm(column_set, tie_set)
                      }
                      rm(pairs, types, subnets, ties)
                  }
                
                # Assigning final scores to global environment
                  assign(x = 'multiplex_edge_correlation', value = multiplex_edge_correlation,.GlobalEnv)  
              }else{
                edgelist <- edgelist[,]
                multiplex_edge_correlation <- 'Simplex Network'
              }
            }
            
          # Calculating System-Level Measures
            largest_weak_component(g)
            largest_bicomponent(g)
            assortativity_degree(edgelist, g)
            reciprocity_rate <- ifelse(as.logical(directed)==TRUE,sna::grecip(g, measure='dyadic.nonnull'), sna::grecip(g, measure='correlation'))
            trans_rate(g)
            global_clustering_coefficient <- sna::gtrans(g,mode=gmode, measure='weak')
            average_geodesic(g)
            multiplex_edge_corr(edgelist, as.logical(directed))
        }else{
          edgelist <- edgelist[,]
        }
        
      # Outputting Network Objects
        assign(x = 'edgelist', value = edgelist,.GlobalEnv)  
        assign(x = 'nodelist', value = nodes,.GlobalEnv)  
        assign(x = net_name, value = g,.GlobalEnv)
    }
    
  # Generating Report
    # System-Level Data Object
      if(package =='igraph') {
        # Creating Component Aggregate Measures
          num_clusters <- igraph::clusters(g, mode="weak")[[3]]
          proportion_largest <- max(igraph::clusters(g, mode="weak")[[2]])/nrow(nodes)
      
        # Creating system-level data object
          multiplex_edge_correlation <- ifelse(type==FALSE, 'Singleplex Network', multiplex_edge_correlation)
          multiplex_edge_correlation <- multiplex_edge_correlation[[1]]
      
          measure_labels <- c('Number of Components', 'Proportion in the Largest Component',
                              'Degree Assortativity', 'Reciprocity Rate', 'Transitivity Rate', 
                              'Global Clustering Coefficient', 'Average Geodesic',
                              'Multi-Level Edge Correlation')
          measure_descriptions <- c( 'The number of weak components in the graph', 
                                     'The proportion of nodes in the largest weak component of the graph',
                                     'Edgewise correlation of degree', 'The proportion of directed ties that are reciprocated',
                                     'The proportion of two-step paths that are also one-step paths',
                                     'The proportion of closed triangles to all triangles', 'The average shortest path length',
                                     'Multiplex networks edgwise correlation of relations')
        measures <- c(num_clusters, proportion_largest, degree_assortatvity, reciprocity_rate,
                      transitivity_rate, global_clustering_coefficient, average_path_length,
                      multiplex_edge_correlation)
        system_level_measures <- cbind(as.data.frame(measure_labels), measure_descriptions, measures)
      
      # Removing node-level and system-level data objects for clarity
        rm(measure_labels, measure_descriptions, num_clusters, proportion_largest, degree_assortatvity,
           reciprocity_rate, global_clustering_coefficient, average_path_length,
           multiplex_edge_correlation, measures)
      
        rm(betweenness, bonpow, closeness, constraint, eigen_cen, in_degree, out_degree,
           total_degree, weighted_degree)
      
        rm(transitivity_rate, reachability, envir = .GlobalEnv)
    }else{
      # Creating Component Aggregate Measures
        num_clusters <- sna::components(g, connected='weak')
        components <- sna::component.largest(g, connected = 'weak', result='membership')
        proportion_largest <- length(components[components==TRUE])/nrow(nodes)
        rm(components)
      
      # Creating system-level data object
        multiplex_edge_correlation <- ifelse(type==FALSE, 'Singleplex Network', multiplex_edge_correlation)
        multiplex_edge_correlation <- multiplex_edge_correlation[[1]]
      
        measure_labels <- c('Number of Components', 'Proportion in the Largest Component',
                            'Degree Assortativity', 'Reciprocity Rate', 'Transitivity Rate', 
                            'Global Clustering Coefficient', 'Average Geodesic', 'Multi-Level Edge Correlation')
        measure_descriptions <- c( 'The number of weak components in the graph', 
                                   'The proportion of nodes in the largest weak component of the graph',
                                   'Edgewise correlation of degree', 'The proportion of directed ties that are reciprocated',
                                   'The proportion of two-step paths that are also one-step paths',
                                   'The proportion of closed triangles to all triangles', 'The average shortest path length',
                                   'Multiplex networks edgwise correlation of relations')
        measures <- c(num_clusters, proportion_largest, degree_assortatvity, reciprocity_rate,
                      transitivity_rate, global_clustering_coefficient, average_path_length,
                      multiplex_edge_correlation)
        system_level_measures <- cbind(as.data.frame(measure_labels), measure_descriptions, measures)
      
      # Removing node-level and system-level data objects for clarity
        rm(measure_labels, measure_descriptions, num_clusters, proportion_largest,
           reciprocity_rate, global_clustering_coefficient, multiplex_edge_correlation, measures)
      
        rm(betweenness, bonpow, closeness, constraint, eigen_cen, in_degree, out_degree,
           reachability, total_degree, weighted_degree)
      
        rm(degree_assortatvity, transitivity_rate, average_path_length, envir = .GlobalEnv)
    }
    
    # System & Node-Level Visualizations
      x11(width=10.6806, height=7.30556)
      system_plot <- function() {
        # Creating Layout
          viz_matrix <- matrix(c(10,10,10,10,10,10,10,10,10,
                                 2,2,2,3,3,3,0,0,0,
                                 1,1,1,1,1,1,4,4,4,
                                 1,1,1,1,1,1,0,0,0,
                                 1,1,1,1,1,1,5,5,5,
                                 1,1,1,1,1,1,6,6,6,
                                 1,1,1,1,1,1,0,0,0,
                                 1,1,1,1,1,1,9,9,9,
                                 7,7,7,8,8,8,0,0,0), 
                        ncol  = 9, byrow = TRUE)
          layout(viz_matrix)
      
        # Defining degree distribution coordinates
          y_axis <- density(nodes$total_degree)$y
          x_axis <- density(nodes$total_degree)$x
          coordinates <- cbind(as.data.frame(x_axis), y_axis)
          coordinates <- coordinates[(coordinates$x_axis >= 0), ]
          x_axis <- pretty(coordinates$x_axis)
          y_axis <- pretty(coordinates$y_axis)
          x_spacer <- x_axis[c(length(x_axis))] - x_axis[c(length(x_axis)-1)]
          x_spacer <- x_spacer*0.5
          y_spacer <- y_axis[c(length(y_axis))] - y_axis[c(length(y_axis)-1)]
          y_spacer <- y_spacer*0.5
      
        # Defining Base Degree Plot
          par(mar = c(5,6,2,2),  family='HersheySerif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(min(x_axis), max(x_axis)), 
               ylim=c(min(y_axis), max(y_axis)), cex.axis=1.3, family='HersheySerif', 
               las=1, main=' ', bty='n')
              grid(lwd = 2)
      
        # Adding Margin Text
          mtext(side = 1, text = 'Total Degree', col = "black", line = 3, cex = 1.5, family='HersheySerif')
        mtext(side = 2, text = 'Density', col = "black", line = 4.5, cex = 1.5, family='HersheySerif')
      
        # Plotting Degree
          lines(coordinates$x_axis, coordinates$y_axis, col='brown', lwd=1.5)
      
        # Adding Skew and Kurtosis
          skewness <- moments::skewness(nodes$total_degree)
          kurtosis <- moments::kurtosis(nodes$total_degree)
          text(x = (max(x_axis)-x_spacer), y = (max(y_axis)-y_spacer), paste('Skewness',round(skewness, digits=2)), cex=1.3)
          text(x = (max(x_axis)-x_spacer), y = (max(y_axis)-(y_spacer*2)), paste('Kurtosis',round(kurtosis, digits=2)), cex=1.3)
      
        # Adding Title
          title(c("Total Degree Distribution"), family='serif', cex.main=2)
      
        # Populating Subplots
          for(i in seq_along(system_level_measures$measure_labels)) {
            plot_measure <- system_level_measures[i,3]
        
            plot_measure <- ifelse(i < 8, as.numeric(plot_measure), plot_measure)
            plot_measure <- ifelse(i < 8, round(plot_measure, digits=2), plot_measure)
            plot_measure <- ifelse(i == 8, trimws(gsub('Edge', '', plot_measure)), plot_measure)
        
            par(mar=c(0,0,0,0), family='serif')
            plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
                 ylim=c(1,10), axes=FALSE, main='', bty='n')
        
            text(x=5, y=9, system_level_measures[i,1], family='serif', font=2, cex=1.3)
            text(x=5, y=6.5, plot_measure, family='serif', cex=1.5)
            rm(plot_measure)
        }
      
        # Adding Plot Title
          par(mar=c(0,0,0,0), family='serif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
               ylim=c(1,10), axes=FALSE, main='', bty='n')
          text(x=5.5, y=5, 'System-Level Measures', family='serif', font=2, cex=3)
      } 
    
      g <- cowplot::as_grob(system_plot)
      p_1 <- cowplot::ggdraw(g)
    
      p_1 
    
      node_measures_plot <- function() {
        # Specifying nicer labels
          if(directed == TRUE){
            plot_labels <- c('Weighted Degree', 'In-Degree', 'Out-Degree', 'Closeness', 
                             'Betweenness', 'Bonacich Power Centrality', 'Eigenvector Centrality', 
                             'Constraint', 'Reachability')
          }else{
            plot_labels <- c('Weighted Degree', 'Closeness', 'Betweenness', 'Bonacich Power Centrality',
                             'Eigenvector Centrality', 'Constraint', 'Reachability')
          }
      
        # Isolating the measure being visualized based on whether it's directed or not
          if(directed == TRUE){
            plot_measures <- c("weighted_degree", "in_degree", "out_degree",     
                               "closeness", "betweenness", "bonpow", "eigen_cen",
                               "constraint", "reachability")
          }else{
            plot_measures <- c("weighted_degree", "closeness", "betweenness", 
                               "bonpow", "eigen_cen", "constraint", "reachability")
          }
      
        # Defining the layout used 
          if(directed == TRUE){
            viz_matrix <- matrix(c(10,10,10,10,10,10,10,10,10,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   7,7,7,8,8,8,9,9,9,
                                   7,7,7,8,8,8,9,9,9,
                                   7,7,7,8,8,8,9,9,9), 
                                ncol  = 9, byrow = TRUE)
            layout(viz_matrix)
          }else{
            viz_matrix <- matrix(c(8,8,8,8,8,8,8,8,8,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   1,1,1,2,2,2,3,3,3,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   4,4,4,5,5,5,6,6,6,
                                   7,7,7,0,0,0,0,0,0,
                                   7,7,7,0,0,0,0,0,0,
                                   7,7,7,0,0,0,0,0,0), 
                                  ncol  = 9, byrow = TRUE)
            layout(viz_matrix)
        }
      
        # Generating Subplot
          for(i in seq_along(plot_measures)){
            # Eliminating NA Values
              plot_measure <- nodes[,plot_measures[[i]]]
              plot_measure <- plot_measure[!is.na(plot_measure)]
            
            # Defining degree distribution coordinates
              y_axis <- density(plot_measure)$y
              x_axis <- density(plot_measure)$x
              coordinates <- cbind(as.data.frame(x_axis), y_axis)
              coordinates <- coordinates[(coordinates$x_axis >= min(plot_measure)), ]
              x_axis <- pretty(coordinates$x_axis)
              y_axis <- pretty(coordinates$y_axis)
        
          # Defining Base Degree Plot
            par(mar = c(5,6,2,2),  family='HersheySerif')
            plot(0, type='n', xlab=' ', ylab=' ', xlim=c(min(x_axis), max(x_axis)), 
                 ylim=c(min(y_axis), max(y_axis)), cex.axis=1.3, family='HersheySerif', 
                 las=1, main=' ', bty='n')
            grid(lwd = 2)
        
          # Adding Margin Text
            mtext(side = 1, text = plot_labels[[i]], col = "black", line = 3, cex = 1.3, family='HersheySerif')
        
          # Plotting Degree
            lines(coordinates$x_axis, coordinates$y_axis, col='brown', lwd=1.5)
        } 
      
        # Adding Title
          par(mar=c(0,0,0,0), family='serif')
          plot(0, type='n', xlab=' ', ylab=' ', xlim=c(1,10), 
               ylim=c(1,10), axes=FALSE, main='', bty='n')
          text(x=5.5, y=5, 'Node-Level Measures', family='serif', font=2, cex=3)
      }
    
      g <- cowplot::as_grob(node_measures_plot)
      p_2 <- cowplot::ggdraw(g)
    
      p_2
    
    # Assigning Report Elements to the Global Environment
      assign(x = 'system_measure_plot', value = p_1,.GlobalEnv)  
      assign(x = 'node_measure_plot', value = p_2,.GlobalEnv)
      assign(x = 'system_level_measures', value = system_level_measures, .GlobalEnv)
      dev.off()
  }

###############
#   netread   #
###############

  IDEANet_Utilities$netread <- function(package="network", network_object=network) {
    # Network Control Logic
      if(package == "network"){
        # Getting Edgelist
          edges <- as.data.frame(network::as.edgelist(network_object))
          colnames(edges) <- c('i_id', 'j_id')
        
        # Checking if there are edge values
          if(length(network::list.edge.attributes(network_object)[network::list.edge.attributes(network_object) != "na"]) >= 1){
            edge_attribute <- network::list.edge.attributes(network_object)[network::list.edge.attributes(network_object) != "na"]
            edge_value <- network::get.edge.value(network_object, edge_attribute, unlist = TRUE, na.omit = TRUE, null.na = FALSE, deleted.edges.omit = TRUE)
            edges$weight <- edge_value
          }else{
            edges$weight <- 1
          }
        
        # Extracting Nodelist 
          nodes <- network::get.vertex.attribute(network_object, "vertex.names")
          nodes <- as.data.frame(cbind(seq(1, length(nodes), 1), nodes))
          colnames(nodes) <- c('id', 'label')
          rm(edge_value)
      }else if (package == 'igraph'){
        # Getting Edgelist: iGraph
          edges <- as.data.frame(igraph::as_edgelist(network_object, names=FALSE))
          colnames(edges) <- c('i_id', 'j_id')
        
        # Checking if there are edge values
          if (length(igraph::get.edge.attribute(network_object)) > 0) {
            edge_values <- as.data.frame(igraph::get.edge.attribute(network_object))
            edges <- cbind(edges, edge_values)
          }else{
            edges$weight <- 1
          }
        
        # Extracting nodelist
          nodes <- as.data.frame(igraph::get.vertex.attribute(network_object))
          colnames(nodes)[[1]] <- c('id')
          nodes$id <- as.numeric(nodes$id)
          nodes$id <- nodes$id + 1
      }else{
          network_object <- network_object
          print('Package Not Supported')
      }
  
    # Outputting Network Objects
      assign(x = 'edges', value = edges,.GlobalEnv)  
      assign(x = 'nodes', value = nodes,.GlobalEnv)  
  }
